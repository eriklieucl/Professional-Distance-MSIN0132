Self-Driving Cars: Ethical Responsibilities of Design Engineers

Abstract:
In the wake of the exposure of Volkswagen's diesel engine test-rigging, a Bloomberg Business journalist described the company as "driven by engineering-crazed executives" [2] and The New York Times ran a story noting how with today's complex computer systems in automobiles, there are numerous opportunities for misdeeds both by automakers and hackers [3]. With the advent of so-called autonomous or self-driving cars, such issues may become even more pervasive and problematic. From a legal perspective, a key focal point is who would be at fault if and when an accident occurs [4]. Much also has been written about the ethical complexities posed by self-driving cars [5]-[6]. In accordance with Moore's Law, "[a]s technological revolutions increase their social impact, ethical problems increase" [7]. Yet relatively little has been said about the ethical responsibilities of the designers of self-driving cars.

When you come to a fork in the road, take it.

—Yogi Berra [1]

In the wake of the exposure of Volkswagen's diesel engine test-rigging, a Bloomberg Business journalist described the company as “driven by engineering-crazed executives” [2] and The New York Times ran a story noting how with today's complex computer systems in automobiles, there are numerous opportunities for misdeeds both by automakers and hackers [3]. With the advent of so-called autonomous or self-driving cars, such issues may become even more pervasive and problematic. From a legal perspective, a key focal point is who would be at fault if and when an accident occurs [4]. Much also has been written about the ethical complexities posed by self-driving cars [5]–[6]. In accordance with Moore's Law, “[a]s technological revolutions increase their social impact, ethical problems increase” [7]. Yet relatively little has been said about the ethical responsibilities of the designers of self-driving cars.

In this paper, we review Richard De George's classic article on the moral responsibilities of engineers in the infamous Pinto case, and consider whether his analysis is valid in an era of pervasive and autonomous technologies [8]. We undertake a contemporary analysis of the topic as it pertains to engineers who are designers of self-driving cars, including by applying the “Moral Responsibility for Computing Artifacts: The Rules,” a framework developed by an ad hoc interdisciplinary group of computing professionals, engineers, and ethicists [9]. While engineers and engineering managers are not necessarily “crazed,” we argue that ethical analysis needs to be integral to the design of self-drlving vehicles. Engineering and other relevant communities need to engage with the issue of what it means to uphold one's ethical and professional responsibilities in the era of these vehicles. Designers of the technology should dillgently and creatively exercise their moral sensitivity capacities in order to uphold their obligations to the public. Integrating this activity into their decision-making process is a critical element in the realm of “anticipatory technology ethics” as defined by Brey [10] and in the realm of “responsible research and innovation” as described by Sutcliffe [11].

Brey's anticipatory technology ethics requires diligence in terms of forecasting consequences; cross-referencing a technology's description with moral values and principles; and evaluating and elaborating on the ethical issues identified [10]. Sutcliffe contends that responsible research and innovation includes an emphasis on the involvement of society throughout a technology's development; paying close attention to ethical and environmental impacts; effective oversight mechanisms; and openness and transparency. [11] As we shall see, self-driving cars bring all of these aspects into sharp focus.

Scope of Use and Potential Benefits of Self-Driving Cars
Self-driving cars are starting to make their way onto the roads in the United States and in other countries. Many automobile manufacturers, including Mercedes-Benz, General Motors, Toyota, and Tesla have a keen interest in creating these cars. It is interesting to note that Silicon Valley companies, including Google, Apple, and Uber, are seeking to become key players in this market even though their history is not directly tied to the production of cars [12]. According to Edward Taylor, by 2025 projected global sales of “semi-automated” cars is approximately 22.7 million, whereas for “highly automated” cars it is 9 million [13]. At the present time, driving responsibilities within a self-driving car are normally shared between a human being and a computing system. The degree to which this hybrid design cedes control to a human versus an automated system varies greatly depending on the company that created the car.

The touted benefits of such cars include improved safety, in part because they could remedy problems associated with distracted driving and other human driver errors. The U.S. National Highway Traffic Safety Administration suggests the “critical reason” that accidents occur is attributable to the driver approximately 94% of the time [14]. The Association for Safe International Road Travel claims that “(n)early 1.3 million people die in road crashes each year” and “(a)n additional 20–50 million are injured or disabled” due to such crashes [15]. According to computer scientist Moshe Vardi, “So by automating driving, we could save about a million lives a year” [16]. Along related lines, advocates of self-driving cars suggest that the accidents involving them are normally the fault of human drivers and not the technology [17]. Allegedly, these cars could also increase fuel economy, decrease traffic congestion, and may ease parking-related problems [18]. Furthermore, the technology may grant more mobility to those who are currently unable to drive, including those with disabilities [19].

The U.S. government has indicated its intent to support self-driving cars. In January 2016, the Obama Administration announced that in the FY 17 budget, it would request a $4 billion investment over ten years for technology R&D and infrastructure improvements related to self-driving cars [20].

Our Focus
Much of the discussion at the intersection of ethics and self-driving cars has to date focused on high-level ethical dilemmas that might be encountered by a self-driving car, such as the trolley problem [5], [21]–[22]. While these dilemmas are important, many other, subtler ethical issues relating to self-driving cars demand the attention of engineering, engineering ethics, and other related communities. Discussion has also tended to focus on the role of programmers or “coders” in dealing with ethical dilemmas and self-driving cars [23]. While the line between a “designer” and a “coder” is not always sharp, we offer the following distinction:

Designer - has a say in determining design pathways (e.g., whether the system will rely on user input); responsible for higher level decisions.

Coder - largely tasked with implementing what the designer specifies; responsible for lower level decisions.

Although not all automotive designers are engineers, engineers are usually involved in the design, development and testing of safety-critical systems. We seek, then, to discuss the ethical responsibilities of design engineers (hardware and software) throughout the process of the design, development, and testing of self-driving cars.

De George and the Pinto Case
The series of Ford Pintos built in the 1970s is a frequent jumping off point for analyzing engineering decision-making and an engineer's ethical responsibilities. De George provides a thorough examination of the Pinto case, largely through the lens of what an engineer should be ethically permitted or even required to do in response to a situation of that type [8]. More specifically, what should an engineer do if the placement of the Pinto's rear fuel tank might cause harm to the public? While we are not committed to the view espoused in the article, the article is important to examine for at least two reasons. First, De George's article helps to bring to light many of the key ethical responsibilities that engineers have in complex, hierarchical organizations. Second, his analysis is directly connected to one of the most notorious and influential automobile engineering ethics cases (a case that is also often discussed in the context of business ethics).

De George contends that engineers must uphold the (safety) standards of the time; such standards are a minimum threshold that their designs must not fall below [8]. Furthermore, he believes that customers are entitled to know how much safety a car has. He offers a list of criteria for when it is: 1) morally permissible to report an issue to the public, and 2) when it would be morally obligatory. Yet in general he suggests that engineers should not be required to challenge managerial decisions (especially since doing so may put their career on the line). He argues that the primary responsibility for correcting such problems should fall on regulators and not engineers (a view we do not embrace).

Human beings, engineers included, have a natural (psychological) tendency to react to a “disaster” and then implement changes afterward. It can be challenging to garner the necessary will and resources towards solving a problem before the problem manifests itself. Further-more, “failure” is often seen as what instructs designers in terms of creating a safer, “better” technology [24]. At least some corporations adopt the mindset of waiting for regulators and/or legal liability to push them towards the implementation of a safer design (i.e., the same effect as De George's approach). However, as should be made abundantly clear by the deaths in the Pinto case, that type of attitude can cause significant harm to the public.

Technical and Other Related Complexities of Self-Driving Cars
The self-driving car can reveal several potential weaknesses inherent to De George's view and to traditional approaches to engineering challenges. The Pinto case and many other examples of automobile safety have focused on an individual component or on interrelated set of components often with a known fault (e.g., the GM ignition switch [25] or Takata airbags [26]). Much of the coverage of self-driving cars in the popular media has likewise been focused on components, particularly sensors for navigation and guidance, and on algorithms for safe driving [27].

A self-driving car, however, is an entire system at least part of which operates “autonomously.” According to the 2016 SAE International standard J3016, the levels of automation of self-driving cars range from 0 to 5 as indicated in Table 1 [28].

Level 2 automation is already being incorporated into existing commercial vehicle brands including Mercedes, BMW, and Cadillac. The Tesla (Model S) incorporates Level 2 and some aspects of Level 3 automation which, as discussed later, has led to some accidents including at least one fatal incident. In this paper, we primarily seek to examine ethical issues related to Levels 3, 4, and 5. A key distinction among those levels is whether the “safety-critical driving functions” are fully entrusted to an automated system (Level 5) or whether a human being is supposed to retain control over those functions in at least some situations (Levels 3 and 4).

A myriad of technical complexities, some of which are described below, could interfere with the safety and reliability of self-driving cars. For example, a typical self-driving car is estimated to contain 100 million lines of code, which is approximately 10 times the amount of code in a fighter jet [13]. Software testing has always been difficult [29]; this kind of complexity makes it even more challenging. We should also keep in mind that it is not just the amount of code and its complexity that is worrisome; it is also the variety and uncertainty of situations that the system will face [30].

Table 1. Levels of driving automation (adapted from SAE [28]).

The complexity of a self-driving car's system architecture, including subsystems for the human interface, route planning, environment perception and modeling, and vehicle hardware actuators, all interconnected with a coordination and control module [31], could generate many outcomes that are difficult to anticipate. This is further complicated by the variability of the design pathways that different car manufacturers are pursuing. The volume of and interconnections between sensor data that have to be processed may (arguably) be a bigger problem that the sheer amount of code, especially given how such data must be processed in a short amount of time in order for a car to react promptly enough. Smooth and timely calibration across light detection and ranging (LIDAR) or other sensors is essential and difficult [32]. The associated complexity is increased by potential variables such as vehicle-to-vehicle (V2V) communication, cloud connectivity, and smart highways, all of which could intensify the need to process vast quantities of information almost instantaneously.

Some of the advantages anticipated for automated cars are predicated on all vehicles being automated. If cars with human drivers are allowed to mingle with self-driving cars, an automated system will be much more difficult to design and test. However, even if human drivers are phased out, a collection of autonomous cars will still be part of a socio-technical system of enormous complexity. The design, development, and testing of swarms of robots is an area of research that is relatively young [33], but it seems clear that much progress will be required before a swarm of vehicles will be able to interact and operate safely [34]. The emergence of “normal accidents” (also known as “system accidents”) is likely unavoidable due to the interactive complexity and tight coupling of the involved technical systems [35]. Intentional tampering (e.g., Volkswagen Diesel emissions tests) and hacking (e.g., Jeep Cherokee case) [36] are also legitimate sources of concern.

Another consideration is whether and how the Eliza Effect [37] might manifest itself; in other words, how might users deceive themselves in terms of a self-driving car's abilities? At times, an engineer's design choices directly contribute to the likelihood of a user's self-deception; for example, utilizing human-like features on a robot can lead users to inaccurately anthropomorphize the technology [38]. Users already seem to have a predisposition to develop an over-reliance on digital outputs as, for example, in the case of the Therac-25 radiation therapy machine [39]. Significant harm, and even death, can result from over-trust of computing technology, including in cases where it has led to airplane crashes [40]. Along these lines, a study by Robinette and colleagues indicates that participants may place too much trust in a robot during a simulated emergency situation even when the robot seems to be malfunctioning [41].

An added variable is that some companies are pursing design pathways that do not require the user to be actively involved in the operation of the car [42]. The underlying paternalistic logic of harm prevention may be well-intended, but numerous unintended, and potentially disastrous, consequences could result. While the list below highlights potential user-centered problems, they have a direct bearing on the designer's decisions and actions:

Will the lack of control over the car cause a user to panic even when it is functioning normally?

Which types of important information might the user miss? For example, will the user be attentive enough to notice if someone is trying to hack into the car?

Will the user's driving skill diminish over time [43]?

Will the user know how to respond if the car is “in trouble” especially if there is no steering wheel or other obvious means for intervening? Or if there is, would grabbing the wheel place the user (and others) at greater risk than letting the system handle the situation by itself?

With regard to the last point, a similar issue has emerged for airline pilots when they are relying on or interacting with an auto-pilot that may be malfunctioning [40], [44]. An overarching concern about normalization of deviance with regard to user behavior can certainly emerge as well [45]; in short, if they are not actively, cognitively engaged in the vehicle's operation, users will become less diligent about monitoring how it functions (to a point where it can easily be imagined that users could metaphorically if not literally become “asleep at the wheel”). These and numerous other considerations, integrally intertwined with the user's psychology and behavior, must be taken into account by designers.

Relying on Standards
Many scholars, including De George, would stipulate that the “standards of the time” can serve as a crucial means for protecting the public from vehicle-related harms. While engineering standards are necessary, there are many occasions where they are not sufficient. This is saliently illustrated by the Pinto case where engineers satisfied rear-end collision and other safety standards of the time. Standards (whether from governmental entities and/or professional engineering societies) and regulations (federal and state) often have difficulty keeping pace with technological change, a challenge that is especially relevant to emerging technologies [46]. This seems to be occurring in the case of self-driving cars where regulations and standards have indeed been slow to materialize as the technology rapidly develops [47].

Arguably, standards for self-driving cars would have to be more rigorous than they are for traditional automobiles. Established “standards” for many of a car's safety features (e.g., front/rear impact tolerances) can be used to judge at least some of a designer's acts. But self-driving cars bring into the picture added variables for which standards must account; for example, a designer would have to determine how to prevent users from increasing the risk to which they expose themselves if the lack of control over the vehicle causes them to override automated systems.

There will be major challenges even in the most optimistic scenario, in which the cars will have standard interfaces that will encourage reliable interactions with each other and with a central system for coordination. In a less optimistic (but perhaps more realistic) scenario, automated cars will be developed by rival corporations that will be less interested in cooperation and more interested in keeping their competitive advantage. If designers are required to protect trade secrets and market advantage while developing, testing, and maintaining their separate automated car, then achieving system-wide reliability, and verifying that reliability, will be all the more difficult.

And as was previously mentioned, auto manufacturers are pursuing significantly different design pathways (e.g., Google vs. Mercedes). Thus, it will be difficult for regulators to develop a uniform approach to safety standards. Among the crucial divides in the self-driving car industry is whether a human being should remain in the driving loop at least to some degree (Levels 2–4) or whether the system should entirely take over the driving (Level 5). There are conflicting opinions in the engineering community about whether humans should be “artificially engaged” to keep their attention focused on a self-driving car's functioning or whether the car should be fully autonomous [48]. If the former is pursued, then considerations involving the interaction between the human operator and the autonomous system such as Mean Time Between Interventions (MTBI) and Mean Time to Intervene (MTTI) are crucial for designers to address [49].

Another significant divide is whether the safety and reliability of the car's functioning should be tied into an ongoing communication stream between the car and external systems (highway sensors, V2V, etc.) or whether the car should be “smart” enough so that it can operate independently from such input. This is sometimes referred to as the distinction between “connected” versus “automated” autonomous vehicles [50]. Coordination among vehicles that adhere to these distinct paradigms will be difficult.

An Appeal to Engineering Codes of Ethics?
One avenue for designers to obtain guidance on professional matters is through codes of ethics. The “paramountcy clause” from engineering codes (i.e., uphold “the safety, health, and welfare of the public”) is certainly well-intentioned and important, but it can be unclear how to apply it to a particular case, especially when there is a professional difference of opinion or there is not much precedent on which to rely. Little specific guidance is provided thus far by professional codes regarding the design of self-driving cars or other “autonomous” technologies.

In general, beyond promulgating codes, professional societies might be reluctant to actively promote “aspirational” ethical behavior in part because they may lack consensus about which types of “good” behaviors should be openly endorsed. Conflicts between engineering priorities and business priorities may also limit the ability of professional societies to engage in ethics promotion and support [51]. Yet aspirational behavior is precisely what is needed in the case of self-driving cars given how much of an effect the cars will have on the lives and well-being of members of the public.

Moral Responsibility for Computing Artifacts: The Rules
“The Rules,” championed by Keith Miller in collaboration with other computer scientists, engineers, and ethicists were created with the intent of providing guidance to the computing and engineering communities especially with respect to pervasive and autonomous technologies [9]. Unlike codes of ethics, The Rules do provide specific guidance relevant to the design of self-driving cars. The Rules are presented below with an accompanying commentary for each one regarding self-driving cars.

Rule 1 - “The people who design, develop, or deploy a computing artifact are morally responsible for that artifact, and for the foreseeable effects of that artifact. This responsibility is shared with other people who design, develop, deploy or knowingly use the artifact as part of a sociotechnical system.” (emphasis added)

This rule assigns moral responsibility to designers among others for “foreseeable effects.” It is unclear, however, how predictable a self-driving car's (and its passenger's) behavior will be, especially in dynamic or unanticipated circumstances. What a designer can reasonably be expected to foresee is an ongoing source of debate, which is likely to be even more contentious with regards to emerging technologies such as self-driving cars. For example, “foreseeable use” and the designer's “intended use” are not necessarily the same thing [52]. Yet foreseeing how the user and other entities may interact with a self-driving car is particularly important, especially during testing phases; testing that ignores possible use cases will be far less effective.

Rule 2 - “The shared responsibility of computing artifacts is not a zero-sum game. The responsibility of an individual is not reduced simply because more people become involved in designing, developing, deploying, or using the artifact. Instead, a person's responsibility includes being answerable for the behaviors of the artifact and for the artifact's effects after deployment, to the degree to which these effects are reasonably foreseeable by that person.” (emphasis added)

Given that the creation of a self-driving car will result from the collective efforts of numerous individuals, many of the designers will largely be anonymous to users and the general public and perhaps even to their co-designers. Designers may be tempted to say their individual responsibility is “reduced” when the technology behaves in a less than optimal, and perhaps dangerous, manner because of how many people are involved in the design (often referred to as “the problem of many hands”), but that type of thinking might not be morally defensible.

Acknowledging that collective responsibility does not negate individual responsibility is critical. Designers and testers are part of a larger community of professionals who have ethical responsibilities for their decisions related to the self-driving car. Designers may experience much external pressure from manufacturers, or others, to weaken or ignore their responsibilities; yet they must seek to uphold the tenets of what it means to be an ethical professional, accepting their individual professional responsibilities.

Rule 3 - “People who knowingly use a particular computing artifact are morally responsible for that use.” (emphasis added)

This rule applies to users but the concept of “knowingly use” may be especially problematic in the case of self-driving cars; for example, when, where, and how to intervene may not be obvious to the human passengers of self-driving cars, especially in a crisis situation. Along related lines, how much knowledge about the technology's functioning is it reasonable to assume that users have? Moreover, how transparent will companies be about how the car is designed to behave when human users circumvent its safety features (e.g., a parent places a child in the car without supervision)?

Rule 4 - “People who knowingly design, develop, deploy, or use a computing artifact can do so responsibly only when they make a reasonable effort to take into account the sociotechnical systems in which the artifact is embedded.” (emphasis added)

Placing the self-driving car on the road is not merely a mundane, incremental step akin to introducing a newer model of automobile. Self-driving cars will be embedded in complex sociotechnical systems encompassing designers, manufacturers, drivers, motorcyclists, bicyclists, pedestrians, and regulators, as well as individual vehicles, roadways, and complex monitoring and control technologies. Interactions among drivers, passengers, pedestrians, vehicles, devices both internal to the car (such as GPS) and external (such as a sensor on the road or a building), and the external environment coalesce into the formation of a highly chaotic, difficult to predict system, especially considering how humans do not always act rationally and can have vastly different risk tolerances and behavioral patterns [53]–[54].

Moreover, not only will the technology of self-driving cars reshape the interaction between car and driver but its introduction will necessitate and be shaped by multifaceted social, legal, and political changes. Many macro-ethical factors will come into play (e.g., differing vehicle types, infrastructure planning, and environmental planning); many policy decisions will need to be made. For example, widespread use of self-driving cars could have a significant impact on urban planning due to the removal of parking spots [48]. In addition to vehicle safety requirements, regulations will be needed in terms of where the vehicles will be permitted to operate and whether a licensed driver must be in the car [55]. Along these lines, many individuals might not have a compelling need to obtain a driver's license and this can have far-reaching effects, including if one travels to a region that only has human-operated vehicles.

Rule 5 - “People who design, develop, deploy, promote, or evaluate a computing artifact should not explicitly or implicitly deceive users about the artifact or its foreseeable effects, or about the sociotechnical systems in which the artifact is embedded.” (emphasis added)

How transparent will companies be about how the self-driving car is designed to behave, especially in dynamic or dangerous traffic situations? Market forces and other forms of competition may pressure engineers and companies to present the car as “risk free” or “of minimal risk” to human drivers and passengers. This is already happening to some degree [56]. Yet Google has recently admitted that one of its cars could be blamed for an accident [57].

The first reported fatal accident involving a self-driving car occurred in May 2016. While under the control of its autopilot system, a Tesla car crashed into a tractor-trailer that was making a left turn in front of the car. A Tesla blog post suggested that since the tractor-trailer was white, it might not have been visible against the brightly lit sky to the car's autopilot system. That same post also stated, “Nonetheless, when used in conjunction with driver oversight, the data is unequivocal that Autopilot reduces driver workload and results in a statistically significant improvement in safety” [58].

Lucas Merian notes however that “The problem for Tesla has been that while its Autopilot … offered some (SAE standards) level 3 automation, there was no way to force a driver to retake control of the vehicle; that has resulted in several documented accidents” including a fatal one [59]. Merian goes on to argue that “(T)he problem … hasn't necessarily been that Tesla's Autopilot … isn't performing as promised, but that drivers place too much confidence in it and take their hands off the steering wheel and their attention from the road.” Following the accident, Elon Musk asserted that Tesla is implementing changes to its autopilot system that will purportedly prevent this type of accident from recurring, including limits on how long a driver's hands can be off the wheel and improved radar for recognizing obstacles [60].

One could argue that Tesla's response to the accident is consistent with a number of “the Rules.” The blogger's and Musk's statements seem to be offering a defense that Rule 5 is being upheld by the designers of the self-driving car as long as the public has a reasonably accurate view of the associated risks. The blogger also speaks to Rule 1 in so far as Tesla is claiming that it has considered the risks and is confident that their self-driving car reduces (although clearly does not eliminate) the chance of harm to the public. Rules 1 and 3 are both arguably addressed by Musk's remarks concerning recognition by Tesla that there is a driver in the loop who needs to be considered by the designers. Nevertheless, the fact that such accidents have occurred with automation in the range of Level 2–3 suggests, as we argue below, that vehicles in the range of Level 3–5 automation should not be permitted on the road until more thorough testing has been conducted.

Our Proposal
People who design, develop, deploy, promote, or evaluate a computing artifact about the artifact or its foreseeable effects.
In the interest of public well-being and safety, designers, testers, managers, and others should sincerely engage with “The Rules” and contemplate their implications for decision making regarding self-driving cars. At an individual level, each designer should consider his/her ethical obligations in terms of creating safer technology. One approach that incorporates this type of thinking is value-sensitive design, which encourages designers to consider how the user's cherished values, such as autonomy, can be upheld while in the process of creating their technologies [61]–[62].

It is also essential that relevant professional communities become collectively involved in a deliberative and reflective process. More specifically, engineering, computing, and other communities should engage in a variety of activities related to anticipatory ethics, including how they can take steps to minimize the impact of system failures in self-driving cars. This could be akin to an “Asilomar-like” activity. Asilomar was a conference in 1975 where scientists gathered to discuss recombinant DNA research and then developed voluntary guidelines to help protect the public.

Unlike Asilomar, however, efforts concerning autonomous vehicles should be structured so as to include the views of stakeholders from outside of the science and engineering community [63]. This activity could be patterned after efforts being witnessed in other realms of emerging technology. For example, the BEINGS conference gathered together scientists, philosophers, lawyers, industry representatives, and others to discuss the ethics of gene editing technologies [64]. Stakeholders from across the globe have organized numerous events, including United Nations meetings, to address concerns about the use of military robots [65]–[66].

How transparent will companies be about how the self-driving car is designed to behave, especially in dynamic or dangerous traffic situations?
Following De George, customers are entitled to know about vehicle safety; this requires extraordinary transparency regarding self-driving cars due to technical complexities and inevitable tradeoffs occasioned by this new technology. Given that a broad and diverse base of users, with vastly different levels of education, may come to rely on the technology, legalistic and obtuse user agreements are unlikely to suffice.

In addition, we would argue that the makers of automated cars should be held accountable for their designs. Before any deployment, each company should demonstrate through carefully monitored trials on test driving tracks that the introduction of its system will not degrade road safety. This testing should take into account the issues raised above, including the interactions between competing brands of cars and with human drivers. While we anticipate that this requirement will add time to any eventual adoption of self-driving cars, we contend that this measure is appropriate considering the importance of protecting the public.

Requiring a demonstration of public safety before a product is released is not unprecedented. In fact, such demonstrations are routinely required of, for example, drug companies. We expect that automated cars may have more of an impact on public safety than any individual new drug or medical device. Therefore, detailed safety trials before deployment seems not only prudent but should be a minimum requirement. Unlike De George, we argue that responsibility for such safety trials should not rest primarily with managers and regulators; rather, for the reasons stated in this paper, we believe this shared responsibility should also be reflected in the ethical and professional behavior of engineering designers of self-driving cars, even in the face of external pressure from management or other entities. The fact that such requirements have not heretofore been enforced, since cars with significant levels of automation are already on public roads, suggests that in the case of automated cars, economic forces and technological momentum have superseded the public good; this inversion of values should be halted and reversed.

The Social Metaverse: Battle for Privacy

Abstract:
Recent advances in technology are rapidly changing the way we interact with the physical world around us. As a result, our digital footprint and digital breadcrumbs are tracked and can reveal not just our identity but also our location, age, shopping preferences, friends, favorite movies, and much more. In the worst case, such tracking may lead to hostile entities coming to know your highly sensitive information such as credit card numbers, social security identity numbers, mother's maiden name, medical history, bank account information, and so on. Social engineering [1] is one of several related ways that this data becomes jeopardized. Furthermore, Internet-connected cameras allow consumers, companies, and government agencies to record animate and inanimate objects in a specific geographic area. Such recordings may be stored in cloud-based storage farms, viewed by humans, or analyzed by machines for various purposes. The information can be gathered and interpreted in multiple ways, such as by surveillance cameras, and can include activity and location inference as well as aggregation and pattern detection.

Recent advances in technology are rapidly changing the way we interact with the physical world around us. As a result, our digital footprint and digital breadcrumbs are tracked and can reveal not just our identity but also our location, age, shopping preferences, friends, favorite movies, and much more. In the worst case, such tracking may lead to hostile entities coming to know your highly sensitive information such as credit card numbers, social security identity numbers, mother’s maiden name, medical history, bank account information, and so on. Social engineering [1] is one of several related ways that this data becomes jeopardized. Furthermore, Internet-connected cameras allow consumers, companies, and government agencies to record animate and inanimate objects in a specific geographic area. Such recordings may be stored in cloud-based storage farms, viewed by humans, or analyzed by machines for various purposes. The information can be gathered and interpreted in multiple ways, such as by surveillance cameras, and can include activity and location inference as well as aggregation and pattern detection.

JUNGIN219/ISTOCK

By and large, we are surveilled and sensed in many aspects of life. This includes: at home (e.g., smart grid energy monitors, ISP/Wi-Fi), while commuting (e.g., EZ-Pass, Google Traffic/Maps, fitness devices), in public spaces (e.g., public safety cameras and sensors, storefront cameras, webcams, etc.), and at work (company firewalls, corporate email, and Internet usage monitoring). In many cases, we are not even aware that such recordings and analyses take place and, hence, our privacy may be in jeopardy in ways we do not anticipate. Here we distinguish several types of privacy (derived from [2]), including:

Privacy of personal info: Any information that reveals something about physical, medical, physiological, economic, cultural, or social status.

Privacy of behavior: Any information about habits, activities, choices, etc.

Privacy of communications: Any data and metadata relating to personal communications.

Note that sometimes we accept a loss of privacy in exchange for security (in the case of security surveillance) or in exchange for useful customization (e.g., personalized advertisements). We also, sometimes unwittingly, freely offer up much of our personal information. For example, our mobile GPS location and device characteristics may be shared ubiquitously, and our social media posts may have a surprising reach (e.g., 150 000+ “friends of friends” [3]). Nowadays, as virtual reality (VR) applications increase in popularity and fidelity they also threaten to erode our privacy in new ways ranging from knowing how we physically move around to the patterns of our neural activities [4].

In this article we focus on technology underpinnings that will help VR participants increase the degree of privacy while immersed in social VR, and builds on our past research in privacy and gaming analytics [14], [15]. Though coined quite some time ago, we use the term metaverse with the same semantics as in Wikipedia [16]: “a collective virtual shared space, created by the convergence of virtually enhanced physical reality and physically persistent virtual space, including the sum of all virtual worlds, augmented reality, and the Internet.” We use the term social metaverse to describe the above sorts of virtual realities in which a central purpose is socialization and interaction with other avatars — including both players and non-player characters (NPC’s). Examples of software systems considered social metaverses today include: Facebook Spaces, AltspaceVR, Sansar, High Fidelity, and many more. While the social metaverse may or may not include capabilities such as gamification, realistic physics, realistic 3D models, user-created content, or in-game economies, it is the complexity and nuance created by the presence of other avatars (human or not) that most motivates our work.

Let us define the term “avatar” (or “agent”) as a visible character within the social metaverse, constrained by the rules of the metaverse. We’ll also use the term “user” (or “player”) to connote a human who operates one or more avatars. Notably, the social metaverse:

Is implemented by an engine that provides the computational basis (“rules of the game”) for all aspects of the world including physics, appearance, communication, synchronization, etc. The engine is in sole control of the consistency and durability of the metaverse.

Hosts avatars who cannot hide from the engine itself (if the engine attempts to surveil or analyze avatar activities, it may do so) nor can they perform actions not offered via metaverse API’s.

Is sometimes editable in the sense that avatars can affect the virtual world (e.g., create or destroy objects).

What is also true about the social metaverse is that, just like in the real world, those avatars who most skillfully use the capabilities of the world in the best way possible may experience a competitive or social advantage over others. We do not consider this to be a nefarious “gaming of the system” but simply using it better. Avatars, for example, may leverage a metaverse application program interface (API) and perform their own sort of surveillance and there is no guarantee that their actions or intents are ethically sound. For example, in-metaverse stalking is a dubious — but often allowable — kind of interaction with these worlds.1 The metaverse will surely be underpinned by data analytics (DA) software components and combined with big data analytics and machine learning in order to provide the developer with insights into how users employ their services [4].

The stage, in our opinion, is therefore set for a battle for privacy within the social metaverse. While it may seem at present that little is at stake, one should note that it is possible that a good deal of our future lives may play out within these metaverses, including performing productive, meaningful work, exchanging important ideas, and using valuable digital currencies.

Motivation and Current Landscape
We have described how the stage is presently set for a privacy battle. This section provides more detail and some examples to corroborate this view. We also survey some of the academic work in this realm.

In the virtual reality metaverses seen in Hollywood movies — e.g., “The Matrix” and “Ready Player One” — participants often experience a level of fidelity indistinguishable from the real world [5]. The antagonists in these movies (but sometimes also the protagonists) often have special powers gained from their uniqueness or some sneaky shortcut. While the hacking of metaverse software underpinnings is an interesting field of its own [6], we neither consider it further here, nor require the presence of malignant insiders in order to justify this work. Current problems with identity theft, harassment, and more, within Massively Multiplayer Online Role-Playing Games (MMORPG’s) further justifies our research. Related work on the causes and nature of in-game harassment (known as “griefing” in the realm of video games) indicates that social dominance orientation (a personality trait characterized by preference of hierarchical groups) is a strong predictor of online sexual harassment [7] and that lower-skilled male players are more likely to harass female players [8].

In 2014, the hashtag #gamergate mobilized a vast gamer campaign of ultimately criminal harassment (including threats of violence and rape) targeted at several women in the gaming industry. Within the game Second Life — an open world social metaverse — abuse and harassment were significant enough to warrant harassment “primers” by Linden Labs. One such primer offered the following advice: “If someone (or something) is pushing you or physically assaulting you inworld, sit down! Sitting prevents most physical forces from affecting your avatar” [9].

Another type of clear and present threat is that of social engineering hacking, a form of trickery that relies on human (victim) interactions that create a sense of urgency, fear, or other emotions, that lead to the individual revealing (unwittingly or not) something of value [1]. Avatars controlled by nefarious human users can easily engage in deceptive and unethical practices such as impersonation, white lies, and manipulation. For example, through observation over time an individual could impersonate a player’s friend to obtain secret or private information. Such players might be annoying and, in the worst case, could jeopardize both player privacy and the pleasure of interacting with the metaverse.

Finally, while the present rapid advances of machine learning (ML) in various sectors — such as art, humanities, advertising, and chatbots — is paying dividends, there is also a potential darker side. Software-driven avatars — armed with ever-growing training data sets — can employ machine learning to nudge human avatars in ways that would best serve their purposes. When combined with social engineering this becomes a threat to privacy. For example, using in-game observations and logging, an ML-backed agent could come to know what your tendencies are, what kind of personality you have (such as impulsive, introverted, etc.), and what kinds of social interactions form the best “nudges” to create particular outcomes [10]. Furthermore, it will eventually be nearly impossible to differentiate between exclusively software-driven (e.g., chatbots, gamebots) and human-driven avatars. Indeed, detecting gamebots using analytic techniques is an active research field [11], [12].

Privacy Mechanisms in the Metaverse
Before describing some of our approaches to privacy we note that in the social metaverse all avatars must “play by the rules.” What does this mean? Both the metaverse and the avatars are software, but the latter cannot exist without the former and the actual implementation underpinnings of the metaverse are accessible to avatars only through controlled means. An example of an access method into the underpinnings of the metaverse might be an API that allows an avatar to ask the metaverse for a list of other avatars presently within 100 distance units. In response the metaverse might return a list of avatars along with descriptive metadata such as skillset, interests, hometown, etc. Suppose that a direct API for listing nearby avatars was not available. It may still be possible for avatars to build up a similar capability through more primitive capabilities. For example, one capability might invoke a “snapshot” feature (to capture a rasterized image of the current scene from the avatar’s point of view), and then call yet another module that picks out and enumerates the avatars in snapshots. Table 1 provides a summary.

We envision a new layer of controls that help tighten privacy in a metaverse where all avatars are essentially empowered by the same capabilities and act within the “rules of the game.” Even with this assumption, however, significantly unethical, bothersome, and threatening behaviors might nonetheless still emerge. Consider that another avatar may: a) watch or follow you incessantly, b) monitor you from a distance, or c) harass you with its presence or utterances. The next sections address our approaches to mitigate these types of undesirable interactions.

Mechanisms
In this section we describe the mechanisms we believe will be useful in the battle for privacy. We view these as fundamental examples of tactics that will help improve privacy, but we recognize that other examples exist. These mechanisms are implemented in software and can exploit the primitives offered by the metaverse which we assume will include primitives that help enact movement, inventory, observation, and analysis of the metaverse. The broad goal of these mechanisms is to help ensure privacy while not utterly destroying the benefits of being in the metaverse. For example, while players could avert all threats to privacy by simply not entering a particular metaverse, this solution is too extreme to meet our requirements. The mechanisms should generally not come at the expense of participation in the metaverse or at the expense of interactions with other agents, objects, virtual storefronts, etc. To these ends, we define two important notions: privacy plans and confusion:

Privacy Plan: A particular set of steps, initiated by an avatar, that enacts changes in the social metaverse such that the avatar has less risk of privacy intrusion when the plan is enacted. A plan can be thought of as a sort of program, written over the allowable metaverse API, that is carried out over a period of time.

Confusion: Creating a confusing effect in nearby agents can be an essential part of an avatar’s privacy plan. Whether or not nearby agents are human or non-player characters, a confusion tactic is intended to reduce the fidelity of these agents’ knowledge of the avatar’s activity, current or future position, possessions, interests, beliefs, and so on.

Note that in large social metaverses — as in MMORPG’s — there is already a level of “cognitive load” introduced by the mere presence of other characters and such loads can ultimately diminish enjoyment of the experience [13]. Our work focuses on the more tangible and aggressive forms of privacy intrusions such as harassment and observation. The remainder of this section outlines privacy plans we have designed to help maintain privacy within the metaverse. Note that these are logical plans, not tied to any particular metaverse platform or specific app.

Plan A — Confusion — Creating a Cloud of Clones
In time, a complex metaverse will provide users with compelling reasons to want to confuse other avatars in their observable region. While interacting with other avatars will remain a principle pleasure (and main raison d’etre) of any social metaverse, it is likely that at times the sheer annoyance caused by some avatars (e.g., malicious strangers or bots), the sheer number of observing avatars, and the possibility of harassment or stalking (when another avatar simply follows you everywhere, essentially recording your experience) will make confusionary tactics attractive. One scenario warranting scrutiny is as follows: You are in a part of a metaverse that resembles a shopping mall in which many virtual (and real) products can be purchased at a multitude of storefronts. While each store may record your transactions, you may desire to obscure your movements from store-to-store from other avatars who you do not know nor trust. Why? For the same reason that an individual would not like to be followed shoulder-to-shoulder in a real mall while buying personal items, groceries, and books. Shopping habits can be highly predictive of other personal behaviors. In the metaverse it will be even easier to be observed by an annoying or malicious agent. Others can steer their avatars near yours, they see the view of the world that you do, and by following along with your avatar, observing and recording your avatars’ interactions with others, store visits, and all other interactions that are observable, a detailed set of data about your habits can (in theory) be created. In another simpler scenario, you may simply be “hanging out” in the metaverse nearby a home you have created for yourself consisting of a building, a yard, and a lake. Here you may simply like to remain free from observation by peers while you stroll between the parts of your property — a reasonable desire indeed.

We refer to one of our privacy plan classes as the “cloud of clones” plan. This plan’s purpose is to bathe the environment with confusion in order to obfuscate user location, activities, beliefs, desires, and/or intentions. In this plan the system creates one or more avatar “clones” which have the same or similar appearance to that of the user’s avatar. The clones may move about autonomously so that observers get confused and may not be able to tell which avatar is under the control of the actual human user. When clones are initiated the user may specify which behaviors are preferred for which subset of clones using command semantics such as: a) “assign all clones a behavior that has high randomness and high interaction levels,” b) “assign half of the clones the behavior named ‘walk around a house’ and the other half of the clones the behavior named ‘walk in circles.’” Behaviors may have additional configurable characteristics (e.g., the circles to be traced out might be 5 meters or 10 meters in diameter and/or might be centered on a specific location or on a specified object) and require specification of metadata such as: number of clones to spawn, duration of plan, spatial configuration, and more. Typically, a clone might closely resemble the user’s avatar, but in principle, variants on clone rendition might include those that vary visually (and randomly) from each other (e.g., all wearing different colored virtual shirts or hairstyles). Each clone implements its behavior by performing in the metaverse, after which the plan terminates.

Figure 1 illustrates this paradigm in simplified form. Figure 1 (top panel) shows a stylized view of the metaverse in which our hero (avatar B) is near her virtual home. Two other avatars are very near to B, but B would like increased privacy from them. In Figure 1 (middle panel) B chooses, configures and launches the “cloud of clones” privacy plan. In Figure 1 (bottom panel) the plan executes, during which time the real B avatar eludes detection from A and C.

From an in-metaverse observer point of view (say Avatar A or C in Figure 1) the sudden emergence of a group of nearly identical avatars to the user (B in the figure) will create confusion. Importantly, the group contains the user B whose intent is to carry on with her actions without harassment.

It is desired that the sudden appearance and subsequent dispersal of these clones will cause any observers to lose track of the original “copy.” During this time observers may be doing their best to track and analyze the behavior of B, but they would be forced to track all clones of B as well. To this end, the collective behavior of B and its clones is not as interesting when averaged out and it cannot be clear which behavior really typifies B’s desires.

There are potential limitations to this approach which we continue to explore. For example, we presume that other nearby avatars cannot create a defense so as to disallow the creation of new clones, or that other avatars cannot (easily) use a method of locking in on a particular avatar (the original B) and tracking it programmatically. This latter possibility could undermine the sudden attempt at partial anonymity. To succeed over in-metaverse observers who may be identifying and tracking Avatar B in their viewports (the view of the metaverse seen from their avatar) the user might temporarily escape into an area in which observers cannot see him (e.g., a building or room) and execute the “clone” plan from there. So long as the observer does not gain visual access again before the clones are created the plan should be able to provide anonymity as desired. We note here that whether or not another agent could identify a clone by detecting pseudo-random behavior is an open issue. Finally, creating huge numbers of clones has effects on both performance and deployment that we do not pursue further here.

Plan B — “Private Copy”
While the previous section proposes techniques to confuse surveilling avatars or bots, an alternative provides the user with a truly private space where surveillance cannot occur. In the current section, we discuss a class of privacy preserving plans which we call “Private Copy.” In these plans, the user is able to request that a private copy of some part of the virtual world be created for the temporary exclusive use of that user. The corresponding portion of the metaverse in the main fabric continues to exist in parallel and other users and avatars may continue to use the main fabric portion unaffected by the actions of the user in the temporary Private Copy. For example, consider a user who desires a private virtual shopping experience. The user may request a Private Copy of a virtual store or even a portion of a virtual store (e.g., a particular department). For example, the store or department may sell personal items for which the user does not want to be observed shopping (e.g., virtual underwear, companionship services, etc.).

Privacy mechanisms that do not preserve the continuity of the metaverse will not be acceptable to the users they intend to protect.
The metaverse will support an API from which the aforementioned user may create her space. A user interface supported by the metaverse will allow a user to request that the store or the department within the store be produced as a Private Copy. The Private Copy may either be created using resources on one of the metaverse provider’s servers or in the user’s client device. A “Private Copy” indicator should be visible to remind the user that the current experience is taking place in a private copy rather than in the full or otherwise more widely accessible virtual world. Once these steps are taken, the user may shop in the Private Copy of the store without worrying that other avatars or bots are observing. Back in the metaverse, from which the user originally triggered the Private Copy, the user’s avatar might temporarily vanish, or a stand-in “clone” (see previous section) could mark the avatar’s continued presence. The user interacts with the Private Copy for some amount of time, and then exits the Private Copy in order to return to the main fabric of the Virtual World. Figure 2 illustrates the main aspects.

Modifications to the virtual world itself may or may not be carried over from the user’s interaction with the Private Copy. For example, the policy for a virtual world store may not allow avatars to make lasting changes to the environment in the store, and in this case the store environment always has the same appearance, according to the store provider’s design. In this case, any environmental modification or interaction by the user within the Private Copy of the store would be necessarily discarded when the user exits the Private Copy. However, in some scenarios it may be useful to preserve modifications resulting from user interaction within the private copy. For example, suppose the user requests a Private Copy of a park within the virtual world, and then the user builds a gazebo in the center of the Private Copy of the park. The user enjoys the gazebo privately for some time, but then chooses to exit the Private Copy and return to the main fabric of the virtual world. At this point the system would assess the modifications the user made to the Private Copy, and would prompt the user to decide whether these changes should be discarded or preserved. If the user chooses to discard the changes then the Private Copy resources are freed and the user is returned to the (still gazebo-less) park in the main fabric of the virtual world. If the user chooses to preserve the changes then the system “merges” the changes into the main fabric, and thus the gazebo from the Private Copy may be added to the main fabric version of the park in the virtual world before the Private Copy resources are freed. In this case, the user and indeed any other avatar or bot will be able to see and to interact with the gazebo when present in the park. The gazebo would also be present in any future Private Copies spawned from the park by any user.

The nuances of merging changes from a user’s Private Copy into the main fabric may depend on whether other avatars were present in the corresponding main fabric portion of the virtual world during the Private Copy session, and whether those avatars interacted with, modified, or observed that portion. In particular, it is possible for a modification made in a user’s Private Copy to conflict with a modification which a different user made to the main fabric copy of the same portion of the virtual world. For example, a user enters a virtual kitchen room in which a knife is present on a counter. The user requests a Private Copy of the virtual kitchen, and while using the private copy the user picks up the knife and puts it into a drawer. Meanwhile in the main fabric version of the virtual kitchen, a different user picks up the same knife and adds it to his item inventory. When the first user exits the Private Copy of the virtual kitchen, suppose the first user requests his modifications to the virtual kitchen be preserved. In this case, the location of the knife must be resolved – is the knife in the drawer, or is it absent from the kitchen (removed to the item inventory of the second user?) In this case, it seems best to discard the first user’s modification (as it was only witnessed by the first user in the Private Copy), and instead maintain the second user’s modification. This is because the second user would be disturbed if the knife were to “disappear” from his item inventory, and also because additional avatars who observed the kitchen counter in the main fabric would have seen the knife removed by the first user. A change in the Private Copy will typically not have as many witnesses as the corresponding conflicting change in the main fabric. We have examined several ways in which conflicts can be resolved. For example (and not unlike the paradigms of software version control), the system may: a) adopt all changes from the copy into the main world, b) selectively merge changes from the copy into the main world, or c) preserve and merge changes from the copy only when they do not conflict with corresponding changes made in the main world.

A “Private Copy” plan thus gives the user absolute privacy for a limited time in a limited space of the user’s choosing. While the user is immersed in the private copy, the system fabric guarantees that no other avatars or bots will observe the user’s behavior. Of course, if the user chooses to merge private copy changes to the main fabric, it may be possible for an observer to later observe those changes and to deduce some part of the user’s behavior. However, if the user discards changes made to the private copy, then no observable traces will be present in the main fabric, and the user’s privacy will be fully maintained. In summary, we note that spinning up private copies of parts of the metaverse for small groups of avatars poses some IT-related issues such as scale and deployment, which are not detailed further here.

Toward a Framework of Privacy Plans
Once the system is capable of providing the user with a variety of privacy plans, it then makes sense to think of this set of plans as a privacy framework to be presented to the user in a controlled way. For example, the available privacy plans may be organized into a “Privacy Options Menu” that allows easy access to the various tools. Table 2 summarizes (in high level detail) several proposed privacy plan fundamentals that we have described in previous sections (or variants thereof). Though we lack the space to illustrate it, we believe that each of these fundamentals admits to a relatively simple algorithmic plan whose implementation would be useful to privacy-seeking avatars. Figure 3(a) shows the user’s view of a local area of a virtual world. The privacy options menu is available through the user interface – in this example a sunglasses “button” appears in the upper right hand corner of the user’s view. If the user selects this button, the menu of available privacy plans is displayed, as shown in Figure 3(b). The user then selects a plan, for example the ‘Disguise’ plan. In response, the system allows the user to choose the form of the disguise, as illustrated in Figure 3(c). Once the user has configured the disguise, then the user’s avatar takes on the new disguised appearance, and in subsequent virtual world interactions the user’s privacy will be preserved.

Once multiple privacy preserving tools are organized into a framework, it becomes possible to enable richer interaction with the available tools. For example, the framework may allow the user to select and execute multiple privacy plans together in useful ways. Here are some examples where a combination of privacy plans may provide increasing benefits over a single plan:

A user chooses to combine Disguise or Invisibility with Teleport such that the user’s avatar vanishes from its original location and appears at a second location chosen by the user, but at the second location the avatar appears disguised or invisible (as previously chosen by the user). In this way, any avatars or bots observing the user at the original location will lose track of the user when teleport is engaged, and any users or bots at the second location will not “see” the user’s true appearance and thus will not be able to identify the user’s avatar at the second location.

A user chooses to combine the Clones plan with Invisibility such that when the additional cloned copies of the user’s avatar appear, the user’s true avatar simultaneously becomes invisible. Any avatars or bots observing the user before this combination of plans is executed will not only be confused by the appearance of multiple clones of the user, but will be guaranteed to lose track of the user’s true avatar due to the invisibility effect.

A user chooses to combine Private Copy with Teleport so that the private copy of a part of the virtual world selected by the user is created, and the user is then teleported into that private copy. The portion of the virtual world selected for Private Copy may be quite distant from the user’s starting location in the virtual world, for example the user may select this portion using a map-like interface, or perhaps select it from a list of identifiable locations from a menu. In this way, surveilling avatars or bots will merely see the user disappear for a time, and they will not see the user entering or approaching the location on which the private copy will be based.

Figure 4 illustrates a user interface for selection of multiple privacy plans in combination. In this example, the user begins in a park area of the virtual world, as shown in Figure 4(a). The user feels like gambling at a casino across town, but does not want to be seen at the casino. The user selects the privacy options menu as in the previous example, however now the menu allows the user to make multiple selections. In this case, the user selects both Teleport and Private Copy. Once the selection is made, the system allows the user to configure the selected privacy plans. As illustrated in Figure 4(b) the system may display a map interface and may ask the user to select the part of the virtual world on which the private copy is based. The user selects the casino from the map interface. With configuration complete, the system spawns a private copy of the casino and teleports the user into the private copy. The user’s new view is illustrated in Figure 4(c). Note that some visual indication is given in the user’s view to remind the user that he is no longer interacting with the full virtual world, but rather is within a private copy of the casino. The user enjoys gambling at the casino for a time, and then chooses to exit back to the main virtual world. As illustrated in Figure 4(d), the system offers to discard or preserve changes that the user made to the private copy of the casino.

An additional benefit of having a framework of privacy plans is that the system may assist the user in the use of the available privacy plans. While it is nice to have a rich menu of tools for enhancing privacy, these tools won’t have much value if the user doesn’t realize when or how the tools should be used. For this reason, the system monitors the virtual world to detect situations in which a given user’s privacy may be in jeopardy, and in this case the system alerts the user and suggests usage of the tools. How can a system detect when a user’s privacy is in danger? Certain user-independent event patterns may come into play, for example the system might recognize that the user is within view of a crowd of avatars or bots, even if the user does not notice or cannot see these observers.

The context of user interaction is another source of information that can be used to detect when privacy is in jeopardy. For example, the system may detect that the user is about to begin a privacy-sensitive interaction with the virtual world. The user might be entering a virtual bank, for example, or may be starting to shop for sensitive items like lingerie at which point the system could recognize this pattern and suggest the usage of a privacy plan. This recommendation may be based on the location or type of interaction the user is engaged in, as well as the relative proximity of other avatars or bots. The recommendation could also take into account how the user has invoked the privacy tools in the past. For example, if the user has regularly used the Lockout Plan in the past, the system recommends Lockout when it is viable; but if such a plan is determined to be not viable due to local observers already in the space, then the system recommends using a Private Copy Plan.

Deployment
This article has focused on the logical development of privacy plans. To provide real world context, this section provides a high level view of a deployment scheme compatible with the needs of privacy plans in social (VR) metaverses. Figure 5 illustrates that playable metaverses will be served from servers over the Internet. Users (embodied as avatars in the metaverse) connect from their devices and make use of the metaverse engine and the metaverse instance (e.g., M1, M2, …) to become a part of the world. Privacy plan capabilities, such as the ability to: launch and control a plan, monitor a plan, persist a plan, and determine effectiveness of a plan, are functionally coded in a game object called Privacy Manager (PM). Such logic is loaded with the metaverse and is present in the engine on the server and on the clients. For example, if Unity3D is the basis for the metaverse, then the PM is a function that may be invoked in the scene, available through an API. In Unity each part of a metaverse is referred to as a scene, and scenes contain instances of game objects such as player and non-player avatars as well as scenery such as structures and lighting. The implementation of Privacy Plans is compatible with Unity’s functional architecture.

Managing User Privacy
This article focuses on approaches and underpinnings that will help participants manage user-privacy while immersed in virtual reality worlds. A solution is needed because the social metaverse features a) large numbers of avatars, b) “open” capabilities for moving, acting, and interacting, and c) a wide and anonymous user base. These characteristics may align to enable nefarious within-metaverse tracking and surveilling. This, in turn, is likely to be annoying and even dangerous as it may compromise user privacy and personal information.

Our system provides various tools and techniques by which a VR user may preserve privacy and prevent such surveillance by others. The system may, for example:

Provide a means for a VR user to confuse observers with noise and deceptive data.

Allow the user to become “invisible” to other users for some period of time.

Allow a user to inhabit a private copy of some part of the virtual world, so that the user may interact with the private copy unseen by others

These techniques will not be perfect but learning how to measure their efficacy is important. There are many other challenges for successfully deploying such tools, and our next steps are to study these in further detail. We feel that privacy mechanisms that do not preserve the continuity of the metaverse will not likely be acceptable to the users they intend to protect. Therefore, many of the challenges ahead lay at the intersection of algorithms and user experience. The battle has only just begun.

Emerging Drone Services: Challenges and Societal Issues

Abstract:
A recent application using drones for business is the Google project (Wing) approved in early 2019 [25]. Urban Air Mobility projects with drone services, though mainly focusing on delivery of parcels, are taking off in over 60 cities around the world [23]. As with many advances in technology, e.g., smartphones, there is an emergence of a service ecosystem associated with the technology (e.g., an app store marketplace). Similarly, it is not difficult to imagine that a range of services associated with drones will emerge in the near future. The purpose of this article is to discuss the concept of drone services, sometimes referred to as Drones-as-a-Service, and to discuss societal issues with drone services.
The Emergence of Drone Services
A recent application using drones for business is the Google project (Wing) approved in early 2019 [25]. Urban Air Mobility projects with drone services, though mainly focusing on delivery of parcels, are taking off in over 60 cities around the world [23]. As with many advances in technology, e.g., smartphones, there is an emergence of a service ecosystem associated with the technology (e.g., an app store marketplace). Similarly, it is not difficult to imagine that a range of services associated with drones will emerge in the near future. The purpose of this article is to discuss the concept of drone services, sometimes referred to as Drones-as-a-Service, and to discuss societal issues with drone services.

Drone services might be considered an Internet-enabled cyber-physical service, involving the use of drones in providing tangible value, from taking photos, spotting incidents, aerial surveys, accompanying someone home, patrolling an area, to delivering goods. Similar to cloud computing and other IT service architectures, Dibbern [10] classified drone services (i.e., drone computing) into three layers:

Infrastructure-as-a-Service (IaaS) layer: the components of the infrastructure layer consist of all technical infrastructure, including hardware, that is required to deliver a specific service such as the drone itself, the service provider, the third party owner of the drone, the drone station, the power station, and possible payloads that can be mounted or used by an individual or multiple drones.

Platform-as-a-Service (PaaS) layer: the components of the platform layer comprise all software services and frameworks that are placed on the infrastructure’s components, including servers and their management, databases and their management, payload management (including mounted or remote), power management, communication management, and decision management.

Drone-as-a-Service (DaaS) (application) layer: the application layer can be seen as an abstraction layer, providing required communication interfaces between participants from the service provider to the end users. This includes application-specific functions, certificates (e.g., security certificate), mobile apps for drone service clients, and web dashboards.

It should be noted that a company can construct a drone service by renting platform software services (using PaaS) and adding its own application-specific software layer on top of the rented platform, or provide its own platform and application layer services over rented hardware infrastructure.

As mentioned above, drone services can be provided in a number of contexts (e.g., commercial or non-commercial environments). Some examples of drone services are advertising and marketing, flying taxis for goods and people, police work, shark spotting, taking photographs, patroling for crime prevention, surveillance, or data processing and computing, as surveyed in [2]. Also, there is a wide range of drone designs, each with its own implications for deployment, safety, and applicability. Different drone designs and application-specific customizations imply that there is a wide variety of drone services.

Drones can be classified in a number of ways [6, 18, 19, 24,], including by design type, size, altitude, control, application, speed, payload, and endurance. The characteristics of drones that are commonly a deciding factor in their classification are speed, flying time, payload, weight, and design.

Figure 1 summarizes the most common classifications for civilian drones: type-based, size-based, control-based, and altitude-based. These four dimensions are significantly associated with a drone’s speed, payload, endurance, traveled distance, service type, and location type (e.g., indoor or outdoor).

Challenges and Societal Issues
There are numerous interrelated socio-technical challenges for successful deployment and delivery of drone services.

Models of Drone Ownership
A question is whether each person or household could have their own drone or several drones, similar to how households can have one or several cars, or each person having multiple mobile and wearable devices (in the sense of ubiquitous computing). It seems inconceivable for each person to have one (or multiple) drones - given the limitations of air space. It might be that the model of ownership and use of drones is community-based, or commercial-based, rather than personalized. At a future time, a government might introduce regulations relating to drone ownership, and control drone ownership in the form of taxes or paid certificates of operation. It is likely that the type of drone ownership will vary from one person and place to another.

A future scenario where drones are sitting idle at home for a lot of people could create the potential for drone sharing, analogous to car sharing. The pricing efficiency and incentives schemes pioneered by Uber and Airbnb [13] can motivate people to lease their drones for use by DaaS providers.

While we have noted drone-sharing for community-based drone services, and businesses providing commercial drone services, an open question is whether there should be government funded public drone services similar to today’s public transport services.

Request Handling
On drone service provisioning, managing or handling upcoming orders is a key aspect. Depending on the type of service, there are different factors that can be considered. These factors can be broadly categorized as internal factors, derived from within the drone-station perspective, while factors contributed by outside attributes are considered external factors. For example, the number of drones, the number of stations, drones’ lifetime, and speed are internal factors. Price, client request frequency, and areas requiring drone services are examples of external factors. Considering these factors, requests can be initiated by different sources (clients) at different frequencies and at various times. It is possible that service providers are limited by the number of their drones and whether they operate one or multiple stations. Some pertinent issues related to this are: what strategies to employ at the station level or at the drone level in order to maximize their performance, and provide adequate and fair services to a population.

Security and Privacy
Drones are being used to enhance the security level of public and private assets such as in monitoring pipelines, reducing risks of damage or theft, and protecting people [8]. In the context of drone services, however, drones themselves are exposed to many security challenges and issues that may arise relating to their control and to information about service providers, clients, and other stakeholders. For example, hackers can gain control of drones operated by a service provider and use the drones for unintended purposes; also, observing paths of drones can be indicative of certain activities of individuals or companies. According to [16], a drone network is different from traditional wireless networks in that drone networks cover large areas, transmit a large amount of information, and consume more power. Therefore, communication, information and system security protocols will have to be established, implemented, and constantly monitored to ensure that the security of the drone services is not compromised. If drones are allowed to fly over private property, then they must not be used beyond their intended flight purpose — e.g., drones doing delivery should not also be taking photos or capturing unauthorized information during flight. There is recent work in allowing property owners to set privacy preferences so that drones might reroute in order to avoid flying over the properties [4]. Future work might even allow property owners to charge for allowing flights overhead, possibly creating a marketplace around “air real estate.”

Quality Assurance
Like any service delivery, it is important for drone services to provide good customer service and this requires quality assurance systems and protocols. A drone should deliver goods to the correct address and the location within the address, and the timing of the service delivery should be as agreed; the service should be delivered to the right person if applicable, and the drone should be able to return to base. There should also be an ability to enforce controls associated with the service delivery, for example, delivering at a pre-specified time and place. These can be enforced using technology (e.g., drone tracking, smartphone applications, bar codes, and electronic tags).

It is not difficult to imagine that a range of services associated with drones will emerge in the near future, sometimes referred to as Drones-as-a-Service, which will have significant social impact.
Safety, Air Traffic Management, and Regulations
Safety is going to be a major challenge with drone services — not only safety of the drones but of people potentially affected by the drones. As is often the case with the emergence of a new technology or service, there is a lag between the introduction of the technology and the technology safety standards for use (e.g., airplanes have become safer compared to when they were first introduced).

According to [17] some drone safety related challenges include the unsupervised nature of recreational drones and their interactions with commercial drones, air-traffic-management-related issues including the interaction with manned aviation, and issues related to obstacle detection and drone system failures. Gatteschi et al. [15] reinforced the need for rules and regulations, which will allow drones to fly without making them a danger to people and things. They also raised concerns about obstacle detection related issues. The issue of drones dropping out of the sky in case of malfunction, accidents (collisions with other drones and birds), or weather conditions, are of concern to the general population. There are already drone rules in many countries, e.g., in Australia the Civil Aviation Safety Authority (CASA) issues rules regarding drones. It will be important for service providers to follow relevant regulations, with conformance perhaps aided or automated by software. Adherence to certain common technical systems might also be required.

Regulation-supported priority flights paths might also be provided for drones that are used by police, or by emergency services, e.g., to deliver defibrillators [21], or ambulance drones. No one party should be allowed to pay to “own” the sky. Mandating particular “highways in the sky” might be a means to manage the flight paths of drones, requiring wide area connectivity for drones, e.g., using LTE-enabled drones in a UAS Traffic Management (UTM) system, allowing beyond-line-of-sight flights [20].

License plates for drones, analogous to registration for vehicles, are also being developed, using physical tagging [12] or electronic radio-based tagging [9].

Insurance
There is a need to have insurance for drones and drone services so that incidents like physical loss, third party damage, product liability, and failure to provide service can be covered. Third party insurance for drones is already mandatory in many countries including Canada, China, U.K., Germany, and Poland [17]. As drone and drone services become more prevalent, the necessary insurance systems will have to evolve to minimize liability and risk for drone owners and service providers.

Efficiency
The efficiency of drone services has yet to be measured in a tangible way as the services are not yet widely used or fully implemented. The efficiency of any drone service may depend upon several factors. For example, weather inconsistencies, attempted capture by others, malfunction while out on delivery, and security concerns by law enforcement may interfere with the functioning of drone services, making them less efficient. Moreover, the exact energy it would take to serve clients, how this energy would be replenished on a regular basis, and whether it would indeed be more expedient/efficient to use drones instead of alternative delivery methods, remains to be explored in real-world settings.

Another factor that may challenge efficiency is the number of orders that can be serviced in a single delivery and how efficient it would be if the drone would be required to return to the point of origin multiple times in order to process multiple deliveries. Where automation fails, efficiency may also be maintained via human judgement to adapt when the circumstances on the ground have changed. The issue of efficiency relates to safety (in not saturating the sky with drones), yet still providing good quality (e.g., timely, available) drone services.

Environment
Another challenge that drone services may face is the effect of increased drone usage on the environment. This is an avenue that is still under-researched [1]. According to Thaller et al. [22], a higher freight transport volume generates more noise and greenhouse gas (GHG) emissions using traditional transport approaches. In order to reduce the impact of these issues, developed countries could start to move towards green solutions, e.g., drones could be more efficient. While there have been some reports that drones will be environment-friendly as they will not require carbon-based fuels [3], thereby reducing carbon emissions, their other effects on the environment have not been quantified.

There are also issues of aesthetics, as drones will change the skylines of cities. It is perhaps an artistic and scientific challenge to enable drone flights across a city in a way that is aesthetically pleasing. Swarms of drones can be coordinated in flight as an artistic display as in Intel’s 2018 drone display [7] and China’s 1374 drone display [11], both at night, suggesting that it might be plausible to have night flights actually be a spectacle, rather than a disturbance, if choreographed or scheduled well. Another major concern associated with low-altitude drones above populated areas, is the noise pollution level [5]. But recent work suggests that drones can be made to fly quietly [14].

More research is needed on the environmental impact of drones in urban and rural environments in order to inform policymakers and the general public.

Widespread Adoption Uncertain
In this paper, we discussed the concept of civilian drone services, and highlighted the wide range of drone-types and their associated applications. We then outlined societal issues and challenges towards their widespread adoption and usage. It remains to be seen whether drones will be part of daily life as extensively as cars and other land vehicles today.

Smart IoT Devices in the Home: Security and Privacy Implications

Abstract:
Internet of Things (IoT) devices possess network capabilities and contain at least a part of the application logic, i.e., they have the ability to perform Transmission Control Protocol/Internet Protocol (TCP/IP) communications on their own, and can process some of the sensor data. The IoT thus refers to the network of physical objects embedded with electronics, software, sensors and connectivity to enable objects to exchange data with the manufacturer, operator, and/or other connected devices. At the start of this decade, there were an estimated 12.5 billion IoT devices, almost twice as much as the world's population of 6.8 billion people [1]. The number of IoT devices is expected to grow rapidly in coming years.

Internet of Things (IoT) devices possess network capabilities and contain at least a part of the application logic, i.e., they have the ability to perform Transmission Control Protocol/Internet Protocol (TCP/IP) communications on their own, and can process some of the sensor data. The IoT thus refers to the network of physical objects embedded with electronics, software, sensors and connectivity to enable objects to exchange data with the manufacturer, operator, and/or other connected devices. At the start of this decade, there were an estimated 12.5 billion IoT devices, almost twice as much as the world’s population of 6.8 billion people [1]. The number of IoT devices is expected to grow rapidly in coming years.

These technological changes have tremendous implications for decentralized production control in manufacturing, and are expected to trigger a fourth industrial revolution, following the steam engine, the conveyor belt, and the computer revolution. IoT devices will have a transformational effect on the lives of everyday consumers, too. Australia’s largest telecommunications company, Telstra, says the average Australian household in 2017 had 13 Internet connected devices and that by 2021 a typical home will have over 30. It’s predicted that the collective value of the smart home market in Australia will be greater than AU$1billion annually by 2021 [2]. As the IoT technology becomes embedded in televisions, webcams, smoke alarms, fitness trackers, climate-control systems, lightbulbs and more, it has the potential to save money and time, help people stay fit, healthy, and safe, and enable effortless communication with friends and family. There are important security and privacy implications for consumers [3], however; many Internet-connected devices have poor in-built security measures [4] and can reveal private data and information that may harm or embarrass consumers [5]. A 2015 inquiry into data retention by the Parliamentary Joint Committee on Intelligence and Security (PJCIS) [6] mentioned “privacy” nearly 400 times. It said that privacy and security concerns “are closely related, as the potential for security breaches has significant ramifications for the proportionality and privacy risks associated with the proposed scheme.”

IoT Consumer Research: Scenario, Test, Evaluate, Propose
In this article, we examine the security and privacy implications of selected IoT devices, building on previous work [7] in this area. Our specific contributions are as follows: First, we developed hypothetical scenarios of household IoT usage. We then tested the security and privacy vulnerabilities of several of these devices, subjecting them to hostile targeting under laboratory conditions. Next, we invited IoT suppliers, consumers, insurers, and regulators to evaluate our results at a workshop. Finally, after examining their reactions and discussing their expectations, we proposed possible approaches to help mitigate the identified risks. We also identified a research trajectory that would begin a new four-step cycle of Scenario-Test-Evaluate-Propose. We wish to emphasize that the workshop phase of our research cycle is as critical as the other phases, and not merely an afterthought. It is this phase that enables us to engage with consumers and understand the contexts in which they use their devices. In doing so, we are in a better position to construct realistic scenarios to guide our laboratory testing.

Scenarios
We created four scenarios in which people are likely to use IoT devices. Our aim was to identify products they would purchase so that we could evaluate their vulnerability under laboratory conditions. All the characters and locations are fictitious, but the scenarios are extremely realistic, and constructed on the basis of direct engagement with consumer advocates.

In the first scenario, the consumer is Tuan, a mid-career private investigator who lives by herself in a regional town in Australia, regularly drives to Melbourne and flies to Sydney to meet with clients. Most of her work involves insurance fraud although she is often asked to track cheating spouses. Because she travels quite a bit, and meets a lot of unusual people in her line of work, Tuan is worried about leaving her home unattended. Knowing the benefits of surveillance tools, she believes that installing IoT devices would offer some peace of mind. As a sole occupier who desires home security, Tuan buys three IoT devices:

a Belkin motion sensor to detect movements inside her house;

TP-Link indoor and outdoor motion sensor cameras; and

A Nest smoke alarm to send alerts to her smartphone in case of fire.

In the second scenario, the IoT device users are Joe and Lorna Jones, an elderly couple who live in the inner city. Lorna is a bit hard of hearing, wears a pacemaker, and has respiratory difficulties. She is not a regular user of the Internet. Joe has some mobility problems and relies on his medical-alert device when he’s away from home. Lorna was playing bowls (lawn bowling) the last time he had a fall, and it took hours before he could get help. Their son, Geoffrey, who lives with his family on the Gold Coast 100-km away, wants a way to monitor his parents’ welfare more thoroughly than checking in on Skype every couple of days. He has installed a number of IoT devices in their home to allow him to keep a virtual eye on Joe and Lorna’s health and wellbeing. These devices are:

Blipcare blood pressure monitor, which sends readings to the web for Geoffrey to check;

Withings weighing scale;

Withings sleep monitor;

Awair air quality monitor; and

Netatmo weather station.

In the third scenario, Suresh and Veda Singh live in Sydney’s suburbs. They know they have to cool their west-facing house in summer. Although they’ve trained their three growing children to moderate their electricity usage, it still feels like they’re in a losing battle against the large electricity bill that arrives every quarter. While shopping for smart devices intended for use around the home, they also bought an interactive doll for their youngest child. The cute doll has a microphone that “listens” to the child, and replies in a manner similar to Apple’s Siri. Their purchases included:

a mix of LIFX and Phillips Hue light bulbs for remote-control lighting;

a TP-Link power switch to control their appliances; and

A Hello Barbie talking doll.

In the fourth scenario, a trendy young city couple place a high priority on their social life. Eddie and Jenny like to listen to music in every room of their home, including on their rooftop terrace. They also spend a lot of time on their mobile devices, and subscribe to the major movie-streaming services. Jenny likes watching the latest movies while Eddie prefers playing computer games. Both have busy professional lives and often work nights and on weekends. They have bought the following devices:

Smart TV with Google Chromecast, which plays games and streams videos;

Triby portable speaker;

Amazon Echo voice-activated assistant;

HP Envy smart printer; and

Pixstar photo frame, which automatically syncs photos with their Facebook accounts.

Testing
We selected a number of devices based on the above scenarios as well as on product availability and popularity in Australia, and carried out detailed tests on each (as well as its supplied mobile app and data server). These tests ranged from the simple (capturing wireless transmissions from the device to evaluating the contents of the communication) to the complex (making the device communicate to a fake server, and overwhelming the device with fake query messages). We automated the process in a laboratory to make it easier to reproduce and compare results.

The IoT devices were connected to a home gateway router either through Wi-Fi or via direct connection with an Ethernet cable. The applications for the IoT devices were downloaded onto an Android tablet, which was connected to the same router. Checks were performed from a laptop running a digital testing platform called Kali Linux, which was on the same network as the IoT devices.

Using this setup, we ran basic computerized scripts and penetration testing tools to assess the safety and security performance of each IoT device.

The devices tested were:

Cameras (TP-Link, Belkin, Dlink, Samsung, Canary, Netatmo and Nest Drop).

Motion sensor (Belkin).

Smoke alarm (Nest).

Medical device (Withings sleep monitor, Withings weighing scale).

Air quality monitor (Awair, Netatmo weather station).

Light bulbs (Phillips Hue and LIFX).

Power switches (Belkin and TP-Link).

Talking doll (Hello Barbie).

Photo frame (Pixstar).

Printer (HP Envy).

Controller (Samsung SmartThings).

Voice assistant (Amazon Echo).

Smart TV with Google Chromecast.

Speaker (Triby portable speaker).

The Results section lists full tables of results showing how each device performed in each category. The results of our tests were consistent and alarming. Every device we tested showed some form of vulnerability in integrity, access control, or reflection capabilities. Many were susceptible to attack in a number of ways. The Phillips Hue light bulb and Belkin switch had notably poor security. But there was some good news. Devices such as the Amazon Echo, Hello Barbie, Nest Drop Cam, and Withings sleep monitor were relatively secure in terms of confidentiality. The Echo, in particular, was a top-rated device in security with encrypted communication channels and almost all of its ports closed to outside attack. A vivid illustration of these vulnerabilities can be gained by applying them to our four scenarios.

In the first scenario, a former target of Tuan’s investigation would be able to sit in a car outside her house and deduce her Wi-Fi network password using freely available software. He would then place a cheap battery-powered device beneath her letterbox. This device connects with her home wireless network, capturing all of the information being transmitted by her IoT devices. This information is then sent back to his laptop, which he monitors from his home. Essentially, his device is performing a “man-in-the-middle” attack on Tuan’s motion sensor and camera — both of which send out information that is not encrypted. This makes it quite simple to see video and read motion-sensor information from Tuan’s devices on his laptop at home. He would therefore know when Tuan’s devices have been inactive for a few hours. Surmising that Tuan is away, perhaps in Melbourne or Sydney, he drives back to his parking spot in the street outside Tuan’s home. He uses a denial-of-service attack on Tuan’s motion sensor, cameras, and smoke alarm by bombarding them with a large number of requests. Unable to cope, these devices simply shut down. This ensures that she will never get the smoke alert from her IoT alarm — even though her home has been physically set alight.

In the second scenario, a criminal buys a list of email addresses of people who have recently registered IoT products. One of these belongs to Joe and Lorna Jones. The criminal sends them an email that contains a link to an app that promises technology customers help with their finances. The app, however, has embedded malware that scouts for IoT devices. Lorna is not sure what the email is about but thinks it sounds interesting. Without thinking, she manages to download the app. The malware immediately disables the Joneses’ firewall and enables port forwarding, making them vulnerable to security breaches. Now the criminal is in control. His malware finds unencrypted messages from their weighing scales, enabling him to deduce their names, ages, gender, height and weight. From this, he can start hatching a plan for someone else in his criminal syndicate to steal the Joneses’ identity and take their social security benefits. He can also use Joe and Lorna’s IoT devices to reflect and amplify attacks on other Internet-connected devices. Whenever he likes, he can use the open ports on the Joneses’ Withings sleep monitor, Awair air quality monitor, and Netatmo weather station and use them as part of a network of compromised devices to launch massive cyber-attacks. Note, however, that in general, health monitoring IoT devices do not tend to have many security problems. Although the Awair air quality monitor could stop functioning if it’s forced to deal with a large amount of Internet traffic, it encrypts all data sent to the server.

In the third scenario, an opportunistic neighbor sees the Singhs as a potential soft burglary target. He uses a remote device to deliver malware that snoops on local Wi-Fi traffic. The Singhs’ IoT devices, especially their power switch and lights, provide a good indication of their presence in, or absence from, their home. More importantly, the neighbor can alter the state of the devices. The Phillips Hue light bulbs do not send encrypted information, so he can turn them on or off and change their color and brightness. The LIFX bulbs have encrypted messages but they can be decrypted with little effort. The TP-Link power switch also uses encrypted data but has a very weak key; it can be broken easily. Under certain conditions, the Hello Barbie doll enables outsiders to listen in on conversations while the doll’s talk button is pushed.

In the fourth scenario, a cyber-stalker uses a password-cracking tool to gain access to Eddie and Jenny’s Wi-Fi network. Like many others, they have not changed the default username or password (“admin”) on most of their devices. Once in, the stalker can use simple request functions to get information on what videos and games they play through Google Chromecast — she might even be able to post a threatening text or video on their television screen. She knows their printer is particularly vulnerable. Using the basic Internet Printing Protocol, she can see any documents they have scanned recently or might even print a threatening or obscene message on the device. Although most of Eddie and Jenny’s devices are relatively safe compared with other IoTs tested, the HP Envy printer is an exception. It has poor security protection, with many open ports that are not protected by a password, allowing an attacker easy access. It also allows an attacker to print documents or stop others from printing entirely.

Evaluate
We invited IoT suppliers, consumers, insurers, and regulators to evaluate our results at a workshop. In this section, we discuss their reactions and expectations.

A frequent theme among attendees was that consumer expectations must survive a transition to the digital age. Most consumers of smart-home IoT devices will not scrutinize manufacturers’ license agreements, and they cannot be expected to as the agreements are frequently complex and unlikely to be enforced. They assume that manufacturers or service providers will supply any software updates necessary to continue running their applications. Similarly, consumers expect that a smart-home device placed on their home network will not create a backdoor to other devices in their home. More generally, they expect that technical security is someone else’s responsibility.

We believe this expectation is reasonable in light of consumers’ experiences with non-IoT products. Car buyers, for instance, are only required to ensure that their cars are locked, perhaps parked in a secure garage, and regularly serviced in line with the manufacturer’s specifications. They are not expected to also be automotive engineers, mechanics or locksmiths. And yet, the question persists: how much education is required for a consumer to know that their IoT devices are “safe”? It’s possible to foresee the use of a security “star rating” for IoT devices — similar to energy- or water-efficiency ratings on household appliances — that may allow consumers to make informed purchasing decisions. Such a ratings scheme might enable market forces to decide how important the security and safety of IoT devices are to consumers [8].

Such a scheme is not without complexity of its own. Security ratings, after all, cannot be static, since security threats evolve continuously. The implications of a low security star rating may be unclear to consumers.

Further, the issue of data ownership and its sharing remains murky [9]. Consumers may expect their service providers will not on-sell data generated by their smart-home IoT devices, for example, despite some license agreements allowing just that. Any ratings system, and improvements to consumer decision making, need to take this into account.

For manufacturers, a major gap exists between consumers’ expectations that IoT devices will be kept up-to-date with near-invisible software “patching” and the current reality that many devices simply cannot be updated. While smartphones can be patched with regular updates, the firmware in many IoT devices cannot be patched due to small memory capacity, lack of a management system, the transient nature of network connectivity, or some other issue. In the cases where devices can be updated, the technical demands required to make this happen are beyond the ability of most consumers.

Furthermore, in a world of disarticulated production, it is simply not clear who is most responsible for a security shortfall: is it the company that designs the device, or the one that supplies component software? Or is it the company that supplies the network in which the device is embedded?

Further, manufacturers often focus on price competitiveness rather than security, especially because development costs in this area are high. They are more likely to move quickly to the next, more advanced version of their models because that is where the greatest profit lies. The performance of previous models is not likely to concern them, particularly once they’re out of warranty. Manufacturers are also aware that consumers who own webcams and digital video recorders used in DDoS attacks do not personally know the victims, and are not likely to pay too much attention to security features. In such cases, security is something that affects people who are not involved in the transaction between buyer and seller — an “externality” in economic terms.

Insurers should reconsider their approach to manufacturers and consumers of IoT devices. The cyber insurance market is said to be worth 3billionto4 billion per year, and is growing at 60 percent annually [10]. Companies that sell IoT devices may need to be insured against the possibility that their products may cause harm to their customers, or others. Effective policy is needed to ensure businesses that produce devices unfit for purpose, or that are repeatedly hacked, cannot continue to do so. A business that is compromised, but has taken reasonable steps to resolve the issue — and shows no negligence — should be able to claim on its insurance.

Recently IoT devices have also been made available for extremely intimate and sexual applications with devices enabling remote logging and control [11], even incorporating cameras. In this context other security researchers have identified significant flaws in the implementation of connectivity, privacy, and data management, which they argue is through the poor choice of source code reused from public repositories [12]. In one case privacy protections in the U.S. meant that customers could receive compensation for breaches of their usage data after a court finding that the breach had not been disclosed to customers.

In this context the potential for serious sexual assault leaves device manufacturers clearly open to adverse judgement and reputational damage even if perpetrators of such crimes are difficult to identify and pursue.

For these and other reasons, there may be no feasible market based solution to the issue of poor IoT security, meaning the onus may fall on regulators.

Proposal
Resolution of the security risks identified in our study is hampered by the siloed nature of regulation that is now becoming more broadly applicable due to the expansion of communications and forming the IoT. Functions and objects are the responsibility of discrete government departments and regulatory agencies, but the agencies now find themselves potentially responsible for new areas. Further exacerbating this problem is that regulatory standards and benchmarks that apply in one jurisdiction do not necessarily apply within another.

Medical, traffic control, and building management systems, cameras, light bulbs and cars with driver-assist features use an increasing number of IoT devices, yet are regulated by separate government departments. In Australia for example, the Therapeutic Goods Administration within the Department of Health regulates medical devices, whereas the Australian Communications and Media Authority regulates telecommunications, broadcasting, radio communications, and the Internet, and the Australian Competition and Consumer Commission regulates consumer safety and fair trade. Regulating IoT devices will involve input from elements within each of these entities, and complexity is only likely to increase over time. The Australian government Department of Infrastructure and Regional Development regulates vehicle safety, and may require real-time access to data feeds from vehicles using IoT devices. As driver-assistance technologies develop in cars, the need for cross-departmental attention will increase. As in Australia, today’s regulatory agencies across the world were created to respond to the rise of earlier technologies. The coming IoT revolution will require new regulatory expertise that cuts across the current set of agencies.

We therefore propose a more coordinated and exhortative approach to regulation. Manufacturers will need to be encouraged to build security at the design phase. A “security by default” attitude would see consumers having to deliberately disable rather than deliberately enable security features. A mechanism may need to be found to coordinate software updates among third-party vendors, and to facilitate the coordinated disclosure of vulnerabilities. Here, a role may be found for national cybersecurity agencies, such as the Australian Cyber Security Centre, to coordinate the security knowledge-sharing of developers, manufacturers, and service providers.

Bodies and services that may have been exempt in the past from regulation may also come under future scrutiny due to the evolving need for consumer and community protection. Because of the serious threat to infrastructure, it is conceivable that governments may in the future require Internet service provider networks to comply with network security standards or meet performance benchmarks. Devices provided by manufacturers or Internet service providers to perform network boundary roles, such as home gateways, could be expected to come under higher levels of requirements. This would mean devices shipped with default passwords, for example, could become a thing of the past.

Further research along the lines of the STEP model is needed in order to continue to shed light on the burgeoning field of IoT devices.

Results
Based on the major threats we identified, Figures 1–4 show how each IoT device performed in the four categories — confidentiality, integrity and authentication, access control, and the ability to withstand reflective attacks.

Figure 1.
Confidentiality rating.

Figure 2.
Integrity and authentication.

Figure 3.
Access control.

Figure 4.
Reflection attack.

From this, we gave each device an overall rating for each category. If a device passed a test it was rated “good” (represented by green “A” boxes in the tables); if it failed it was “poor” (red “C” boxes). If it did not pass the test but the attack was unsuccessful, it was rated as average (yellow “B” boxes). The grey boxes show when a particular attribute could not be tested or assessed.

Note these tests were performed at a point in time and may have been improved or further deteriorated since the date of testing in April 2017.

Confidentiality Rating
Confidentially is a measure of the security of data running between the IoT device, the router, and our server.

Our tests show whether the communications sent and received were encrypted (the most difficult to read), encoded (hard but not impossible), or plain text (easiest to hack).

Figure 1 shows how each device performed in confidentiality testing.

Most of the devices had fairly secure communications in two channels (device to server and user app to server) but were vulnerable when they communicated with their user app.

Five of the devices — the Phillips Hue light bulb, Belkin switch and motion sensor, HP Envy printer, and TP-Link camera — sent data in plain text rather than encrypted code. This would make it relatively simple for hackers to deduce when a user is at home, based on whether the power switch is on or off, or when the light bulb was last used, for example.

The TP-Link camera was particularly susceptible to attack. Not only might an attacker view any video and audio footage based on reassembled data, the default authentication password “admin” was easily decoded.

Integrity Rating
We checked the integrity and authentication of each device by setting up a fake server to “listen” on the port used by the real server. This technique is known as a “man in the middle attack.”

Using a number of methods, this fake server communicated with each device to see if it could be authenticated. We also tested to see if the devices could be controlled by outside influences.

Figure 2 shows how each device performed in integrity testing.

These results show that all of the IoT devices were vulnerable to an attack through the Domain Name System (DNS) protocol. This means that attackers could hijack the system and impersonate the legitimate server of the IoT device. They would be protected, however, through proper authentication.

The two light bulbs that were tested communicated with the fake server, which is a concern.

Access Control Rating
We tested to see if any ports on a device were “open,” allowing the port to be exploited by attackers. Based on this, we launched a password-guessing attack to see if they were protected by strong security protocols.

Each device was also checked to see how much traffic any open ports could handle before they were brought down in a DDoS attack.

Figure 3 below shows how each device performed in the access control testing.

Almost all of the devices had some form of open-port vulnerability. This would enable intruders to communicate with or gain access to the devices.

Both the Belkin Smart Cam and HP Envy printer exposed a wide range of open ports.

Disturbingly, both the HP printer and DLink camera had no protection for remote access.

The last three columns show that most of the devices were susceptible to at least one form of DDoS attack.

Reflection Attack Rating
We evaluated all of the devices in their ability to “reflect” traffic and overload a victim’s network, forcing it to shut down.

“Amplification” is a type of reflection attack [13]. In this case, the reflection is achieved by gaining a response from an innocent IoT device to a spoofed IP address (a victim machine or server). During an amplification attack, an attacker sends a query with a forged IP address (the victim’s) to the reflector (the IoT device), prompting it to reply to that address with a response. With numerous fake queries being sent out, and with several IoT devices replying simultaneously, the victim’s network is overwhelmed by the sheer number of responses it’s asked to make.

Figure 4 below shows how each device performed.

Most of the devices were unable to withstand an ICMP reflection attack.

All devices, except the LIFX light bulb, were susceptible to reflecting some form of attack.

The Samsung Smart Cam was vulnerable across a number of protocols.

Current Generation of IoT Devices Vulnerable to Attack
Consumer products connected to the Internet will soon become commonplace in homes and businesses, and will offer customers many productivity and lifestyle benefits. Our study, however, suggests that the current generation of IoT devices is vulnerable to attack in a number of ways. It is a complex problem, and there don’t appear to be any “single bullet” solutions to make IoT devices safer or more secure. We hope this article sets the platform for a dialogue between consumers, suppliers, regulators, and insurers of IoT devices to develop appropriate methods to tackle the problem.

Smart Cities and Their Smart Decisions: Ethical Considerations

Abstract:
In many respects, information and communication technologies (ICTs) pose new challenges to society. It is worth recognizing what ICTs represent within the urban space because of their widespread use and increasing presence in people?s daily lives. ICTs allow new ways of interaction between citizens and communities and, according to many authors, their use can improve not only communication within society, but also public management as a whole. Their use, therefore, favors greater social and economic development.

In many respects, information and communication technologies (ICTs) pose new challenges to society. It is worth recognizing what ICTs represent within the urban space because of their widespread use and increasing presence in people's daily lives. ICTs allow new ways of interaction between citizens and communities and, according to many authors, their use can improve not only communication within society, but also public management as a whole. Their use, therefore, favors greater social and economic development.

At the same time, it seems worth evaluating how such widespread presence of ICTs could in some cases influence the information flow that supports decisions and policies — with negative social impacts if an unethical selection of information that is generated and collected leads to biased political decisions, bringing about greater inequality and discrimination.

Such scenarios become more likely and more potentially dangerous as so-called “smart cities” are increasingly deployed all around the world.

The aim of this study is to foster discussion on some possible consequences of the diffusion of ICTs and their underlying telecommunications infrastructure in the form of smart cities, and to propose some initial elements of an ethical framework to address the irreversible “ICTization” of our societies.

Technological Environment
The present generation of engineering students seems to ignore the processes that created our technological world, especially related to its communication dynamics. For example, not all students are aware of issues such as the digital divide, a complex problem that goes beyond merely technical issues and involves knowing how different users and social groups understand the information accessed through ICTs, in ways that make sense in their specifi contexts.

The very role of technology in contemporary societies is worth discussing. Postman [1] proposes a classification of cultures and their technologies into three categories. In the first one, cultures make use of technology only as a basic tool – subject to the jurisdiction of social values and religious systems – in a culturally integrated way that does not impose contradictions in the worldviews of those societies.

In a second category, cultures function as technocracies in which the adopted tools modify the cultural reality and defy or threaten social customs, myths, politics, and religion. Finally, a third category includes the technopoly, which results from an understanding that social progress only comes from the human ability to apply knowledge to create inventions. Inventing, in the sense of creating new technologies, means changing the world for the better, and this is an irrefutable certainty. Such a significant change undervalues the traditions of social and symbolic worlds, making them invisible and irrelevant.

In this context, one of the basic principles that characterize the technopoly is the absolute need to have access to any information, whenever and wherever necessary. Such certainty is considered one of the main factors of progress.

Of course, many discoveries whose applications have been very useful to society have resulted in services that led to their increasing integration into people's lives. They have then evolved from this initial phase of simple convenience and became necessities. For instance, the development of telecommunications, a key element of ICTs, stands out a process in which technology takes precedence and becomes increasingly essential. Throughout the twentieth century, as Ribeiro [2] remarks, telecommunications entered our social and economic lives, initially as something useful but not essential until eventually the benefits they brought became inextricably integrated into the fabric of our societies, to the level as we know today in which everything depends on its presence.

Communication Systems Build the Modern World
The telecommunications revolution in all its aspects (television, radio, telephony, and data communication systems) connects the world and its different cultures. Its presence enables the technocracy and causes changes in various societies and cultures, bringing about the so-called “global village.” In combination with the computer, another powerful invention, these two technologies renewed and reinforced each other. Rapidly, the digital world was integrated to the telecommunications infrastructure, eliminating the intrinsic differences of legacy systems and established the basic premise of the digitization and convergence of different types of communication structures.

Finally, intelligent and distributed systems, in their many levels, completed the scenario with all the conditions required for the establishment of the technopoly.

Rosa [3] points out that we are indeed living today the technological revolution centered on information and telecommunications. Thus, ICTs became a parameter for life in society. In addition, Postman [1] warns that the technopoly is reductionist in its goals, limiting discussion to efficiency and effectiveness, eventually leading to a loss of focus on the social reality that generated these very informational structures.

ICTs Made Available in a Ubiquitous Manner
The current scenario in which telecommunications services are formed of different network structures creates the conditions for the emergence of the Next Generation Networks (NGN), and therefore, increases the importance of the ubiquitous Wireless Sensor Networks (WSN). According to Aguilar et al. [4], the network of wireless sensors represents an emerging technology that resulted both from the advances of micro-electromechanical systems and from the latest wireless technologies, over the last decade.

According to Evans [5], to meet that demand research on WSN has advanced in a broad range of applications that include monitoring of vehicular traffic in cities or of environmental phenomena, among many other possibilities.

Smart Cities
The convergent role played by ICTs in the daily lives of individuals, companies and governments becomes increasingly important as cities effectively turn into platforms of economic development. This is highlighted by the European Technology Platform [6], an initiative aimed at instigating the development of network capacities as a way to achieve their potential in allowing improvements in the living standard of citizens.

In this sense, Firmino [7] points out that there is a major commitment of planners and technological development agencies to stimulate integrated technological development in many cities and regions worldwide, as a way to create digital smart cities.

However, this transition raises new security issues. According to Deluca [8], although the WSN are backed by a specialized structure with no connection to communication networks, a significant part of these networks can be, and indeed are being, connected to information systems.

Another key issue relates to the privacy of the information monitored by sensors, and to the implications that the violation of this principle can have on citizens' routines and habits in case of malicious or unintentional data exposure. In this context, the International Telecommunication Union (ITU) [9] points out that one of the most important challenges for adopting these emerging technologies in smart cities is in data protection and privacy.

Presence of Power and Authority in the Relation Between Technology and Society
Technological neutrality is the bias that permeates the discourse about the benefits of applying ICTs in smart cities. However, one should note the weakness of this view, as pointed out by many authors. Dagnino [10] describes such a perception of science as a neutral activity carried out by researchers imbued with the purpose of seeking the truth as illusory and disconnected from social reality.

Thus, the reliance on ICTs in the management of smart cities has often been presented as absolutely neutral, whether in smart buildings, in traffic monitoring, in the surveillance of stadiums, or in the monitoring of water flow in basins. Nevertheless, according to Dirks [11], smart cities should have a level of maturity in the collection, processing, and dissemination of information. These requirements are summarized in three specific points: instrumentation (collection and provision of data), interconnection (different systems are interconnected and data are exchanged to produce information), and finally intelligence (with the ability to use the information, modeling patterns, and behaviors).

For Paraense [12], the use of distributed intelligence in the management of smart cities requires a sensor network as an interface between the real and the digital worlds. Ubiquitous Networks (USN) in the structure of smart cities will act as eyes and ears, collecting data and acting as a source of the information required by the city management. According to the IBM taxonomy, this part refers to the instrumentation phase.

Although there are many potential benefits, it is necessary to consider the conditions for the adoption of such new technologies, and to consider the issues related to their acceptance by the population such as data privacy, information security, availability, interoperability, and the provision of the necessary infrastructure as well as an efficient and effective management. This corresponds to the interconnection phase.

Finally, the third and most important part of the process, the intelligence dimension, requires going beyond the strictly technical aspects. When analyzing ICTs' contributions, either positive or negative, to efficiency and productivity or their environmental effects it is not enough to evaluate machines, structures, and systems. The role of specific forms of power and authority should be taken into account in the third phase. After all, the technology is connected with political decisions, and is capable of manipulating reality and of favoring certain social classes.

Winner [13] exemplifies such a problem by mentioning the case of the Long Island bridges. In short, these bridges were built intentionally below the standard height in order to preclude the passage of buses. This action was a way to manipulate society, as this would prevent the black and poor population to get to these so-called sophisticated areas, keeping it exclusive for the middle and upper classes. In such a way, technology granted privileges to certain social groups over the others.

Thus, when it comes to the construction of smart cities, it is very important to understand what underpins their structures and to understand what are the purposes of their sensors. The key issue is then asking whenever city authorities acquire data by means of sensor system, what were the criteria for this acquisition, who is coordinating that data acquisition, and what is being done to avoid manipulations similar to the Long Island bridges case.

Invisible Decisions and Ethical Matters
An analogy could be made in this case: what if “information packets” were thought of as buses and cars coming from different origins (sources), and handled throughout their paths by “bridges,” and then subject to routing criteria not necessarily clear to the society? Based on the source address the “bridges” may decide the preemptions, the queuing, and the speed of processing, and act as strategically located filters. Additionally, the discourse of managers imply that all decisions are based on open and socially-accepted parameters, supported by information based on data obtained from informational structures that operate at full technical efficiency. However, we claim here that this very argument does not unveil the intricacies of certain invisible aspects that untrained eyes are unable to grasp, from the process as a whole, to the manipulations intended to meet specific interests.

It is timely to consider that, although the technopoly could try to deny it, it is necessary to reflect on the construction of smart cities because they can affect the rights of their inhabitants.

These cleverly manipulated cities remind us of the reflections, in Jonas [14], about the role that technology has played in an ethical sense, due to its unique position in human life, in which technology acts as a social ordering entity whose detrimental effects (unintended results caused by the technological developments) cannot be predicted.

A risk pointed out by Postman [1] is the disconnection that the technopoly creates between the information and its human purpose. If the systems lack a human meaning, the information becomes an end in itself, what may distort reality. An even more serious situation would be the conscious intention to manipulate reality, something that can occur in the intelligence phase by means of maneuvers that lead the preceding (instrumentation and connection) stages to address the interests of specific groups.

In reality this invisibility ensures that decision-makers can covertly prioritize the treatment of higher-class areas to the detriment of poorer ones. As an example of this risk, discriminatory treatment to certain social classes was somehow inherent in the digital participatory budget program in a large Latin American city because of the greater access to the Internet in the higher social classes. Hence, a process such as voting over the Internet, which in principle would be essentially democratic, was distorted simply because the citizens from privileged classes made use of their higher digital literacy. In this case, privileged citizens used their greater capacity for network mobilization to change the trend of a given vote to favor a project of their own interest to the detriment of other projects that appeared to be more appealing to other social classes.

In some parts of the world, issues related to ethnicity, culture, or religion could emerge as a result of decisions that lead to a loss of privacy for some minorities. This can happen if technical decisions are motivated by the use of particular physical, linguistic, or cultural characteristics as a basis for discrimination or persecution. For example, it is possible that the algorithms behind video surveillance systems in major European and American cities are trained not only to detect suspicious movements and facial expressions of passersby, but also to direct the search to individuals from specific ethnic groups, supposedly more likely to be linked to criminal or terrorist acts. The same bias may occur with algorithms that analyze voice data in telephony or VOIP services, whenever this results from prioritizing the detection of certain languages or particular types of accent. The decisions that originate in all these unequal treatments might incur embarrassing situations for many citizens simply because they happen to belong to these ethnic or social groups.

Moreover, particularly with regard to privacy of collected information, one can extrapolate a scenario envisioned for digital cities from what already occurs in the deployment of smart energy grids, in order to evaluate the risks involved. Indeed, in many pioneer localities in which the technological transition to smart grids occurred in the last decade there were several violations of the principle of privacy of data collected. In these case, the original purpose of data collection was improving the operating efficiency of the power grid. This goal was distorted to serve various state agents – either police officers, scrutinizing household energy consumption patterns in the search for traces that indicate activities, such as the home production of marijuana for personal consumption, or tax auditors looking for evidences that someone is running a business at home without a license. These are also examples of invisible decisions that, in order to meet specific interests, interfere in information flow, filtering and redirecting data to a different purpose from what it was initially expect to do.

More recently, a massive leak of classified information showed that national security agencies in one country were not only scrutinizing telecommunication data from their own citizens, but also violating the privacy of telecom and Internet users abroad.

Thus, it is necessary to evoke an ethical dimension in order to protect and inform society of such deviations, which may undermine the essential values of citizenship because of decisions disconnected from these values.

As Srour [15] remarks, there is a risk that an economic power could induce partiality and allow unfair standards of conduct to be used to justify opportunistic conveniences with discriminatory and unethical discourse.

It is worth noting here that the adoption of some assumptions might lead to thoughtless choices that have not even been noticed as such. As a result, a network may have been installed at technically incorrect points, or it prioritizes information from certain areas, or it collects data of interest to certain groups and the final reports are generated with manipulation of the collected information, which leads to unreliable statistical results – to name but a few possible problems.

Finally, the technopoly takes full control, undisputed since the decisions were supposedly “technical options” in order to achieve progress and welfare for all.

At What Point Does Transcendence Become Possible?
In a scenario where society is developing digital smart cities, ICTs and communication highways, deployed by governments and companies with varied interests play a key role. But if society decides that it is necessary that development is guided by an ethical commitment to the social good, then who would ensure that all decisions comply to that commitment and who would accept the challenge to constantly reinforce it and make it transparent?

Decisions in the field of information technology (IT) refer to IT governance guidelines that, according to Costa [16], refer to the assignment of responsibilities and decision rights and to the respect for principles, so that this process evolves transparently and achieves the business objectives of the organizations.

In this broader context, the organizations responsible for the informational structures of the smart cities must apply best practices and models in order to transcend traditional decision-making processes. Examples of best practices and models include return of investments in information storage, defense against manipulation, and quality assurance in citizen services, regardless of any economic factors. Vasquez [17] explains that deciding and acting in concrete situations is a practical-moral problem that refers to responsibility, in which the freedom and determinism of the human acts pertain to the realm of ethics.

According to Garcia [18], in the face of a new reality, society should act in a structured and comprehensive way to avoid solutions that meet only the mere sum of private interests. The transforming power of reality should not be based only on economic power, and should encompass ethical values.

Proposal of an Ethical System
According to Elizondo [19], the ethical perspective of technology encompasses economic, social, institutional, and environmental dimensions, and is not limited to scientific and technological contexts.

The role of ethics is to establish limits by means of codes, ordinances, rules, and laws that express social values and guide decisions. Although most laws and regulations aim at altruistic values, according to Pereira and Fonseca [20] there is an inconsistency between ethical discourse and the political and technological decisions.

In this context, one has to afford ethical discourse the possibility of effectively influencing the reality, contributing to a new social scene entailed by smart cities. To make possible the proposal of an ethical perspective, Elizondo [19] states that its implementation would take place through the structuring of a system consisting of axioms, values, norms, and finally, a set of evaluation criteria.

This work proposes, as a contribution to that matter, an anthropocentric axiom, as a perspective that places the human being in the center of society and of its ethical values, without ignoring the human responsibility towards other beings, whose lives have a value that is comparable to ours, and towards the planet itself.

From that axiom it is possible to establish a set of values, ethical values applied to attitudes, behaviors, situations, objects, etc., because human beings are also socio-historical beings. In practice, these values help us understand more clearly the scope of social goals. When properly structured on a scale, values ensure safety in times of crisis, strong social structures, and efficient political institutions. In this proposal some fundamental values are emphasized, such as:

Human dignity, with respect to full human development, guaranteeing fundamental individual rights to everyone;

Freedom, combining cosmopolitanism of minds, individual autonomy, democracy, and transparency of ideas and motivations;

True altruism, in which prevail scruples and respect for the interests of all; and

Justice in which equality and fairness are ingredients of an authentic citizenship.

In this context, a decision depends on a hierarchy of values in which each value is subordinated to a higher one in such a way that the most fundamental values are highlighted. The reasons for that hierarchy of values are manifold, and must not be subject to particular situations. In order to be fully accepted it requires the participation of all.

The third element in the ethical system is represented by norms. These norms connect the values to real situations, allowing decisions to be taken in the accomplishment of duties. Deontological theories assert that the duty must be determined by rules with permanent validity, regardless of the consequences of its application. An action motivated by duty regardless of particular interests or inclinations will then be considered morally good. This becomes possible when the action rests on human rationality and, in this case, the rational imperative implies ethical action.

One can find this concept in Kant's categorical imperative, which prohibits acts that cannot be universalized, and therefore does not admit any exceptions in favor of some individuals. As a rule, all participants involved in the deployment of smart cities are asked to act in compliance with this universal requirement.

A last point to be considered in the proposition of an ethical system is the evaluation system, which will determine if a situation fits into what was established as acceptable within the system. It is proposed here that the determination of what is right does not depend on fixed rules, in such a way that it could be simplistic and decontextualized or could cover for inappropriate actions. The rules must overarch all sorts of consequences arising from a particular decision.

In order to be comprehensive, we suggest resorting to teleology or to the ethics of responsibility to uphold everyone's responsibility in face of all kinds of actions and decisions.

It is worthwhile emphasizing here the reactions that may arise when one sheds light on unethical attitudes, such as a kind of argument that attempts to justify and conceal all the vices of the decisions without clearly explaining them. As Moraes [21] remarks, the fragility of human discourse lies in that it can be used to clarify as well as to disguise its essence behind obscure words. So we should be aware in order not to allow the denial of responsibilities. The decision-makers must assume their responsibilities, and the society must demand that from them.

In the context of the actions related to the deployment of smart cities, we propose a new role for IT Governance: to add an ethical dimension to the realm of responsibilities that arise in face of this new reality, and formulating and issuing guidelines that encompass this new perspective. One should assign rights and responsibilities, in order to allow audit mechanisms and security measures, supported by supervisory committees that can evaluate the IT activities and operations to identify and mitigate ethical problems and ensure total transparency.

This is not a simple task, since according to Mitchan [22], technology poses many challenges to ethics, let alone the tendency of the technopolistic arguments to escape any ethical responsibilities.

Possible Praxis?
In order to ensure that intelligent and distributed information systems effectively correspond to the ethical expectations of society, how is it possible to protect society against the fallibility of all these actors and prevent them from engaging in misconduct? This seems to be the biggest challenge. According to Srour [15], when the ethical issue is widespread it is up to the entire society to organize itself to create the means to audit and supervise the decisions. Thus we propose here the establishment of technical procedures aimed at expanding the boundaries of IT Governance practices, so that informational structures are transparent and always respectful to the agreed values and principles, as protectors of democracy.

As remarked by Mitchan [22], the concept of “responsibility” is a recent concern in the area of ICTs, and only after undergoing a wide range of legal, philosophical, and religious contexts has it found its application in science and technology.

Currently, civil liability applies to workplaces and to the potential hazards of some products. It would therefore be necessary to extend this principle to the new dimensions that result from the expansion of technological power.

It is worth recalling the reflections of Jonas [14], who anticipated the transcendence of the new living standards, and of the non-application of the traditional ethical view. Such an outdated understanding of ethics required a new conception of duties, responsibilities, and rights in which these values should consider the future consequences of procedures whose effects could damage society. The question that emerges refers to the fact that certain attitudes are not guided by ethical responsibility, or by the organizations in charge of digital governance, which create norms and rules, without even conceiving of such a reality.

Finally, some might take advantage of supposed technical neutrality in the name of efficiency and, with the blessing of the technopoly, would deny their responsibilities, and wouldn't even be questioned about the possible consequences of their actions for the future of society.

Essential to Add an Ethical Dimension
The considerations in this article can be enriched by the concerns raised in the Unesco Earth Charter [23] which call for stronger democratic institutions at all levels and for more transparency and publicity in the exercise of power, including participation in decision-making and the access to justice.

Therefore, we ask for the presence of institutions to account for the deployment of new smart cities in conformance with their original purposes. It is of great importance to point out the hidden risks behind decisions that might go unnoticed within society simply because they are based on the argument of technical efficiency.

Furthermore, aware of the inherent non-neutrality of the application of science and technology, the Earth Charter proposes that it is necessary to grant independent access to justice and to administrative procedures. This would allow contextualizing ICT in a bigger picture as an agent of the dominant technopolistic logic, which if left to its own devices would become indisputable.

The Earth Charter stress the importance of upholding the right of all recipients of the information provided by these systems to effectively receive it as originated from trusted sources, properly collected, without any social bias in handling the information along its path. In fact, any manipulation in the information delivery would certainly distort the perception of reality, producing errors and causing detrimental effects in people's lives.

Hence, the Earth Charter reasserts the need to promote the meaningful participation of all individuals and organizations in decision-making, to stimulate and expand the debate among engineers, network specialists, and information systems experts. These professionals will face practical and moral decisions, and the definition of the intelligent information systems operation may bring about conflicts of interest.

Therefore, we can conclude that it is essential to add an ethical dimension in every decision level, defining responsibilities, to hold the policy-makers accountable for their decisions not only in deployment phases, but also during operation. Only such transparency in all decision levels can avoid that distortions caused by biased information could overshadow the benefits of smart cities.

Marshall-tufflex Helps To Keep Stansted Tunnel’s Lighting Upgrade Project On Track

When the lighting and power supply within the Stansted Tunnel needed upgrading, Marshall-Tufflex was the only company able to supply Network Rail’s specified Class 1 GRP cable tray system and meet the tight deadlines J Murphy & Sons has to complete the work.

Opened in 1991 and covering around 1.8km, Stansted Tunnel serves the single, bi-directional track that provides the only rail route in and out of Stansted Airport. A crucial element of the tunnel is the lighting system which caters for safe passenger evacuation in an emergency and provides light for maintenance teams in the tunnel.

Ad hoc repairs and replacements have been carried out to the lighting, but after 30 years of water ingress and general wear and tear, it was clear that it was no longer possible to cost-effectively sustain the lighting by simply replacing the degraded or life expired parts. As a result, J Murphy & Sons was awarded the contract to replace the entire lighting, lighting support systems and power supplies for the tunnel.

The upgrade project involves the installation of a new GRP handrail with integral lighting running along the tunnel wall and the steel walkway, emergency lighting and supporting electrical supplies and Marshall-Tufflex’s GRP cable management system. Timings are critical to the upgrade as work is being carried out to a strict schedule between January 2022 and January 2023, with line closures being restricted to Friday and Saturday nights.

“We had four 50 hour possessions during January and March 2022 which was part of the enabling works and helped us to ensure the project could be completed by the financial year end 2022/2023,” explains Craig Anger, Contracts Engineering Manager, at J Murphy & Sons. “However, when we came to price the GRP tray according to the specification, we found that the nominated supplier had long lead times on its products and wasn’t able to meet our allocated possession dates in January 2022.”

J Murphy and Sons went back to the market and contacted a number of other manufacturers to source a perforated GRP tray but they were unable to meet the possession times against the signed off product specification for the tunnel works. The cable trays had to meet Class 1 fire rating in order to maintain a certain level of fire resistance, whilst still maintaining the integrity of the cabling. In addition to being suitable for the environment, the cable management systems also needed to have a minimum design life of 25 years.

Marshall-Tufflex was the only company able to provide GRP cable management products that met the specific requirements and the tight installation deadlines. The company’s GRP cable trays are lightweight, long lasting and provide high levels of fire and corrosion resistance, making them ideal for challenging rail environments. Furthermore, Marshall-Tufflex is registered with the RISQS Railway Industry Supplier Qualification scheme.

During the January 2022 possessions, J Murphy and Sons removed and replaced 1,800m of handrail and installed 1,800m of Marshall-Tufflex’s GRP cable trays. These trays require fewer components and feature interlocking and self-adjusting couplings which made them quick and easy to assemble and install. 45° bends have accommodated changes in level around recesses in the tunnel wall, enabling the tray to run down and underneath the walkway rather than straight across where it would cause a trip hazard.

Craig further explained: “Barry Roberts, Marshall-Tufflex’s National Specification Manager provided us with all the datasheets including fire test documentation which was a big bonus as Network Rail could see that the products have undergone all the relevant tests. The team at Marshall-Tufflex provided excellent support and ensured all products were delivered to site to meet our strict schedule. This has helped us to keep on track to complete the final cabling installation and commissioning during our January 2023 possession.”

The lighting upgrade project is due for completion in January 2023, by which time J Murphy and Sons will have installed 1,800m of Marshall-Tufflex’s GRP cable management system to house the cabling for the new handrail with integral lighting, all during limited weekend possessions in January 2022 and January 2023.

Direction of Physical Infrastructure as we move into 2021

1. Global trends impacting physical infrastructure in 2021?

National and regional governments are investing in new infrastructure where information technology (IT) and Power-over-Ethernet (PoE) is now a key component of these development plans. Large municipal governments, in particular, are spending more on Smart City projects that provide unique advantages. IT infrastructure developments are gaining momentum, as established and emerging technology applications are adopted by the forward-thinking regions.

The top 100 cities investing in smart initiatives in 2019 represent around 29% of global spending, whether this growth can be sustained due to the current pandemic reducing economic activity among all spenders is yet to be seen.

Use cases related to resilient energy and infrastructure represented over one-third of the opportunity, driven mainly by smart grids. Data-driven public safety and intelligent transportation represented around 18 percent and 14 percent of overall spending respectively.  Looking at the largest use cases, smart grids (electricity and gas combined) still attract the largest share of investments, although their relative importance will decrease as the market matures and other use cases become mainstream. Fixed visual surveillance, advanced public transportation, intelligent traffic management, and connected back-office follow, and together these five use cases currently represent over half of the investment opportunity.

BIM & BMS – Building Information Models and Building Management Systems

As BIM models advance and become interoperable this is driving evermore technology integration into building operation. Ultimately the goal is to develop interoperability between BIM, BMS, IT, IoT and manufacturing based on open standards. As this evolves, one estimate is that more than one billion sensors and connected devices will be deployed globally in buildings by 2021, alongside the billions of mobile connected devices brought into buildings by tenants, workers and visitors.

Figure 1: Building / BMS Network

Outlook for Smart City Applications Growth

Analysts now believe that many governments are moving to incorporate Smart City use cases into budgets, or financing efforts through more traditional means, which is helping to grow further investments.

Looking to the future, more IT infrastructure investment will focus on new technology applications such as artificial intelligence (AI) combined with the internet of things (IoT) and 5G wireless communications.

2. What are the implications of WiFi 6 on cabling infrastructure design?

Category 6A cables are the fastest-growing cabling segment on the market and are recommended for wireless deployments because they are standardised for 10GBASE-T and provide optimal PoE (Power over Ethernet) performance. For best practice, Panduit recommends Category 6A cables for WiFi 5 and higher applications.

WiFi 7 and the Future

The next generation WiFi 7 is currently referred to as extremely high throughput (EHP) and a standard is being defined by the IEEE 802.11be Task Force. While WiFi 6 and WiFi 7 currently can only operate in the 2.4 and 5 GHz spectrums, the FCC plans to allow a new spectrum between 5.925 and 7.125 GHz to open up for Wi-Fi. This new spectrum has 1200 MHz of additional bandwidth as compared to the existing 500 MHz bandwidth in the 5 GHz spectrum and 90 MHz bandwidth in the 2.4 GHz spectrum.

In addition to the new bandwidth, the IEEE 802.11be Task Force is exploring WiFi 7 technologies such as coordinated orthogonal frequency-division multiple access (OFDMA), coordinated null steering, and distributed MIMO to enhance beam forming and employ massive multiple-input and multiple-output (MIMO).

The 802.11be Task Force has a stated objective to use two Category 6A cables per access point to support the required bandwidth and to use an existing and common cable type.

WiFi 6 Advantages

WiFi 6 continues to offer numerous advantages over WiFi 5, which for any organisation planning smart building and smart environment infrastructure allow end device data rate improvement of speed up to 4x. More advantages from OFDMA, beamforming, and improved modulation allows for improved data rates for end devices, which include increased capacity.

Improved performance in in-situ many device environments will benefit from OFDMA, improved MIMO, and beamforming to help improve total capacity, as well as improved performance in environments utilising the 2.4 GHz band which will benefit IoT devices. For many of these end devices manufacturers have increased battery life and Wi-Fi 6 employs a “target wake time” (TWT) feature and directs the Wi-Fi radio when to sleep and wake up to receive its transmission. This reduces power consumption with no impact on performance. Whilst, OFDMA is improving latency performance across the network to under 1ms.

4. Are we going to see the end of copper in data centres now?

With Category 8 availability and its capability to deliver 40Gb on RG45 connectivity, there is still life for copper. The key is if the hardware manufacturers and their customers decide whether the alternative cabling systems offer a comprehensive enough solution, in respect of cost and capability to render copper redundant.

Towards Smart and Reconfigurable Environment: Intelligent Reflecting Surface Aided Wireless Network

Abstract:
IRS is a new and revolutionizing technology that is able to significantly improve the performance of wireless communication networks, by smartly reconfiguring the wireless propagation environment with the use of massive low-cost passive reflecting elements integrated on a planar surface. Specifically, different elements of an IRS can independently reflect the incident signal by controlling its amplitude and/or phase and thereby collaboratively achieve fine-grained 3D passive beamforming for directional signal enhancement or nulling. In this article, we first provide an overview of the IRS technology, including its main applications in wireless communication, competitive advantages over existing technologies, hardware architecture as well as the corresponding new signal model. We then address the key challenges in designing and implementing the new IRS-aided hybrid (with both active and passive components) wireless network, as compared to the traditional network comprising active components only. Finally, numerical results are provided to show the great performance enhancement with the use of IRS in typical wireless networks.

Introduction
The targeted 1000-fold network capacity increase and ubiquitous wireless connectivity for at least 100 billion devices by the forthcoming fifth-generation (5G) wireless network have been largely achieved, thanks to the various key enabling technologies such as ultra-dense network (UDN), massive multiple-input multiple-output (MIMO), millimeter wave (mmWave) communication, and so on [1]. However, the required high complexity and hardware cost as well as increased energy consumption are still crucial issues that remain unsolved. For instance, densely deploying base stations (BSs) or access points (APs) in a UDN not only entails increased hardware expenditure and maintenance cost, but also aggravates the network interference issue. In addition, extending massive MIMO from sub-6 GHz to mmWave frequency bands generally requires more complex signal processing as well as more costly and energy consuming hardware (e.g., radio frequency (RF) chains). Therefore, research on finding innovative, spectral and energy efficient, and yet cost-effective solutions for future/beyond-5G wireless networks is still imperative [2].

Recently, intelligent reflecting surface (IRS) has been proposed as a promising new technology for reconfiguring the wireless propagation environment via software-controlled reflection [3]–[6]. Specifically, IRS is a planar surface comprising a large number of low-cost passive reflecting elements, each being able to induce an amplitude and/or phase change to the incident signal independently, thereby collaboratively achieving fine-grained three-dimensional (3D) reflect beamforming. In a sharp contrast to the existing wireless link adaptation techniques at the transmitter/receiver, IRS proactively modifies the wireless channel between them via highly controllable and intelligent signal reflection. This thus provides a new degree of freedom (DoF) to further enhance the wireless communication performance and paves the way to realize a smart and programmable wireless environment. Since IRS eliminates the use of transmit RF chains and operates only in short range, it can be densely deployed with scalable cost and low energy consumption, yet without the need of sophisticated interference management among passive IRSs. Furthermore, IRSs can be practically fabricated to conform to mount on arbitrarily shaped surfaces to cater to different application scenarios, while the underlying communication modeling and problem need further investigation.

Figure 1 illustrates several typical applications of IRS-aided wireless networks. The first application considers a user located in a dead zone where the direct link between it and its serving BS is severely blocked by an obstacle. In this case, deploying an IRS that has clear links with the BS and user helps bypass the obstacle via intelligent signal reflection, thereby creating a virtual line-of-sight (LoS) link between them. This is particularly useful for the coverage extension in mmWave communications that are highly vulnerable to indoor blockage. The second application shows the use of IRS for improving the physical layer security. When the link distance from the BS to the eavesdropper is smaller than that to the legitimate user (e.g., user 1), or the eavesdropper lies in the same direction as the legitimate user (e.g., user 2), the achievable secrecy communication rates are highly limited (even by employing transmit beamforming at the BS in the latter case). However, if an IRS is deployed in the vicinity of the eavesdropper, the reflected signal by IRS can be tuned to cancel out the (non-IRS-reflected) signal from the BS at the eavesdropper, thus effectively reducing the information leakage. In the third application, for a cell-edge user that suffers both high signal attenuation from its serving BS and severe co-channel interference from a neighboring BS, an IRS can be deployed at the cell edge to help not only improve the desired signal power but also suppress the interference by properly designing its reflect beamforming, thus creating a “signal hotspot” as well as “interference-free zone” in its vicinity. The fourth application illustrates the use of IRS for enabling massive device-to-device (D2D) communications where the IRS acts as a signal reflection hub to support simultaneous low-power D2D transmissions via interference mitigation. The last application shows the use of IRS for realizing simultaneous wireless information and power transfer (SWIPT) to miscellaneous devices in an Internet-of-Things (IoT) network [7], where the large aperture of IRS is leveraged to compensate the significant power loss over long distance via passive beamforming to nearby IoT devices to improve the efficiency of wireless power transfer to them.

IRS proactively modifies the wireless channel between them via highly controllable and intelligent signal reflection. This thus provides a new degree of freedom (DoF) to further enhance the wireless communication performance and paves the way to realizing a smart and programmable wireless environment.
Next, we highlight the main differences as well as competitive advantages of IRS as compared to other related technologies, namely, active relay, backscatter communication, and active surface based massive MIMO [8]. First, compared to active wireless relay that assists in source-destination communication by signal regeneration and retransmission, IRS does not use any active transmit module (e.g., power amplifier) but only reflects the received signal as a passive array. Besides, active relay usually operates in half-du-plex mode and is thus less spectrum efficient than IRS, which operates in full-duplex mode. Although full-duplex relay is also implementable, it requires effective self-interference cancellation techniques that are costly to implement. Second, different from the traditional backscatter communication such as the radio frequency identification (RFID) tag that communicates with the reader by modulating its reflected signal sent from the reader, IRS is mainly used to facilitate the existing communication link instead of sending any information of its own. As such, the reader in backscatter communication needs to implement self-interference cancellation at its receiver to decode the tag's message [9]. By contrast, in IRS-aided communication, both the direct-path and reflect-path signals may carry the same useful information and thus can be coherently added at the receiver to improve the signal strength for decoding. Third, IRS is also different from the active surface based massive MIMO [8] due to their different array architectures (passive versus active) and operating mechanisms (reflect versus transmit).

In practice, field-programmable gate array (FPGA) can be implemented as the controller, which also acts as a gateway to communicate and coordinate with other network components (e.g., BSs, APs, and user terminals) through separate wireless links for low-rate information exchange with them.
Despite its many benefits, the IRS-aided wireless network constitutes both active (BS, AP, user terminal) and passive (IRS) components, thus differing significantly from the traditional network comprising active components only. This thus motivates this article to provide an overview of IRS, including its signal model, hardware architecture, passive beamforming design, channel acquisition, node deployment, and so on. In particular, the main challenges and their potential solutions for designing and implementing IRS-aided wireless networks are highlighted to inspire future research. Numerical results are also provided to validate the effectiveness of IRS in some typical wireless applications.

Signal Model and Hardware Architecture
In this section, we first provide the general signal model for IRS's reflection, and then discuss the IRS's hardware implementation and resultant constraints on the design of IRS reflection coefficients in practice.

Signal Model
As shown in Fig. 1, the composite channel from the BS to the user through each element of the IRS is a concatenation of three components, namely, the BS-IRS link, IRS's reflection, and the IRS-user link. Such a composite channel behaves different from the conventional point-to-point direct channel. Specifically, each element of the IRS receives the superposed multi-path signals from the transmitter, and then scatters the combined signal with adjustable amplitude and/or phase as if from a single point source, thus leading to a “multiplicative” channel model.

Mathematically, the reflected signal by the nth element of the IRS, denoted by yn, is given by multiplying the corresponding incident signal, denoted by xn, with a complex reflection coefficient, that is, yn=(βnejθn)xn, n=1,…,N, where βn∈[0, 1] and θn∈[0, 2π) specify the reflection coefficient and control the reflected signal's amplitude (or attenuation due to passive reflection) and phase shift, respectively, and N denotes the total number of reflecting elements at the IRS. By smartly adjusting the reflection coefficients, the IRS can spatially control the reflected signal to achieve different purposes. For example, to maximize the received power of the user in a dead zone in Fig. 1, all elements of the IRS should set their reflection amplitude to the maximum value of one for maximum signal reflection; whereas to achieve signal/interference cancelation in Fig. 1, the reflection amplitude of IRS elements may not necessarily be equal to the maximum value, and can be set different over the elements. In practice, other factors such as elements' mutual coupling, noise and hardware imperfections also need to be considered in the modeling, and their impact on the performance of IRS is still an ongoing research topic.

Hardware Architecture
The hardware implementation of IRS is based on the concept of “metasurface”, which is made of two-dimensional (2D) metamaterial that is digitally controllable [10]. Specifically, the metasurface is a planar array consisting of a large number of so-called meta-atoms with electrical thickness in the order of the subwavelength of the operating frequency of interest [11]. By properly designing the elements, including geometrical shape (e.g., square or split-ring), size/dimension, orientation, arrangement, and so on, their individual signal response (reflection amplitude and phase shift) can be modified accordingly. In wireless communication applications, the reflection coefficient of each element should be tunable to cater to dynamic wireless channels arising from the user mobility, thus requiring reconfigurability in real time. This can be achieved by leveraging electronic devices such as positive-intrinsic-negative (PIN) diodes, field-effect transistors (FETs), or microelec-tromechanical system (MEMS) switches.

As shown in Fig. 2, a typical architecture of IRS consists of three layers and a smart controller. In the outer layer, a large number of metallic patches (elements) are printed on a dielectric substrate to directly interact with incident signals. Behind this layer, a copper plate is used to avoid the signal energy leakage. Last, the inner layer is a control circuit board that is responsible for adjusting the reflection amplitude/phase shift of each element, triggered by a smart controller attached to the IRS. In practice, field-programmable gate array (FPGA) can be implemented as the controller, which also acts as a gateway to communicate and coordinate with other network components (e.g., BSs, APs, and user terminals) through separate wireless links for low-rate information exchange with them.

One example of an individual element's structure is also shown in Fig. 2, where a PIN diode is embedded in each element. By controlling its biasing voltage via a direct-current (DC) feeding line, the PIN diode can be switched between “On” and “Off” states as shown in the equivalent circuits, thereby generating a phase-shift difference of π in rad [10]. As such, different phase shifts of IRS's elements can be realized independently via setting the corresponding biasing voltages by the smart controller. On the other hand, to effectively control the reflection amplitude, variable resistor load can be applied in the element design [12]. For example, by changing the values of resistors in each element, different portions of the incident signal's energy are dissipated, thus achieving controllable reflection amplitude in [0, 1]. In practice, it is desirable to have independent control of the amplitude and phase shift at each element, for which the above circuits need to be efficiently integrated [12].

Discrete Amplitude and Phase-Shift Model
While continuously tuning the reflection amplitude and phase shift of each of the IRS's elements is certainly advantageous for communication applications, it is costly to implement in practice because manufacturing such high-precision elements requires sophisticated design and expensive hardware, which may not be a scalable solution as the number of elements becomes very large. For example, to enable 16 levels of phase shift as shown in Fig. 2, four PIN diodes need to be integrated to each element. This not only makes the element design very challenging due to the limited element size, but also requires more controlling pins from the IRS controller to excite a large number of PIN diodes. As such, for practical IRSs that usually have massive elements, it is more cost-effective to implement only discrete amplitude/phase-shift levels requiring a small number of control bits for each element, for example, 1-bit for two-level (reflecting or absorbing) amplitude control, and/or two-level (0 or π) phase-shift control [10], [13].

Main Design Challenge
Besides the hardware, we present in this section other main challenges in designing and implementing IRS-aided wireless networks from the signal processing and communication perspective, including passive beamforming design, IRS channel acquisition, and IRS deployment.

Passive Beamforming Design
One challenge of designing the passive beamforming for IRS in practice lies in the discrete amplitude and phase-shift levels of each element. Instead of using exhaustive search, a practical approach is to first relax such constraints and solve the problem with continuous amplitude/phase-shift values, then quantize the obtained solutions to their nearest values in the discrete sets. While this approach is generally able to reduce the computation time to polynomial orders of N, it may suffer various loss in performance due to quantization errors, depending on the number of quantization levels as well as N. To further improve the performance, the heuristic alternating optimization technique can be applied to iteratively optimize the discrete amplitude/phase-shift values of each element by fixing those of all the others at each iteration [13].

One challenge of designing the passive beamforming for IRS in practice lies in the discrete amplitude and phase-shift levels of each element. Instead of using exhaustive search, a practical approach is to first relax such constraints and solve the problem with continuous amplitude/phase-shift values, then quantize the obtained solutions to their nearest values in the discrete sets.
On the other hand, the passive reflect beamforming of IRS in general needs to be jointly designed with the transmit beamforming of other active components in the network such as BS/AP so as to optimize the network performance. For instance, when the BS-user direct link is severally blocked, the transmit beamforming of the BS ought to point toward the IRS to maximize its signal reflection for serving the user. In contrast, when the signal attenuation of the BS-user link is comparable to that of the IRS-reflected link, the transmit beamforming of the BS should be properly designed to strike a balance between the user's and IRS's directions. In the above cases, the reflection amplitude of all elements of the IRS should be set to the maximum value to achieve maximum signal reflection, while the phase shifts need to be tuned based on all channels such that the reflected signal by the IRS can be added constructively at the receiver with the signal directly from the BS.

For the general multiuser setup, an IRS-aided system benefits from not only the reflect beamforming for the desired signal but also the suppression of co-channel interference. For example, the user closer to the IRS can tolerate more interference from a neighboring BS, because the IRS's reflect beamforming can be designed such that the interference reflected by the IRS adds destructively with that directly from the interfering BS to maximally cancel it at the user's receiver. This in turn provides more flexibility for designing the transmit beamforming at the neighboring BS for serving other users outside the IRS's covered region. Despite the above benefits, the active and passive beamforming designs are in general closely coupled and their joint design usually leads to complicated optimization problems that are hard to be solved optimally and efficiently. To reduce such high complexity, alternating optimization can be applied to obtain suboptimal solutions, by iteratively optimizing one of the transmit and reflect beamforming with the other being fixed, until the convergence is reached [4]. Furthermore, wireless networks generally operate in wideband channels with frequency selectivity. While active BSs can use digital processing in frequency domain such as digital beamforming or hybrid digital/analog beamforming to deal with the frequency-selective channel variation [14], it is practically difficult to implement such advanced signal processing for the passive IRS. As a result, the reflection coefficients of IRS needs to balance the channels at different frequency sub-bands, which further complicates the joint active and passive beamforming optimization.

Some interesting results have been reported in this new direction recently [3]–[5], [13]. Prior works [3], [4] revealed that in an IRS-aided single-user system, the received power increases asymptotically in the order of N2 as the number of reflecting elements, N, goes to infinity. In other words, every doubling of N achieves about 6 dB power gain in the large-N regime. The fundamental reason behind such a “square law” of N is that the IRS not only achieves a power gain of N by reflect beamforming (similarly to the transmit beamforming with N active antennas in massive MIMO [14]), but also captures another power gain of N due to its large aperture for collecting the received signal energy from the BS (which is not available in massive MIMO). Moreover, compared to the ideal case with continuous phase shifts, it was shown in [13] that by using IRS with b-bit uniformly quantized phase shifts, the same asymptotic power scaling law of order N2 can be achieved, while only a constant proportional power loss as a function of b is incurred, which is insignificant as compared to N2 for large N and thus can be ignored as N goes to infinity.

IRS Channel Acquisition
The various performance gains brought by the passive beamforming of IRS in general require the accurate knowledge of the channels between the IRS and the involved BSs and users. Note that by turning the IRS into the absorbing mode, the channel state information (CSI) of BS-user links without the IRS can be obtained by applying the conventional channel estimation methods [14]. Depending on whether receive RF chains are equipped with the elements at the IRS or not, the acquisition of CSI between the IRS and BSs/users can be classified into the following two categories.

First, although transmit RF chains are removed from the IRS for cost reduction and energy saving, each of its elements can be equipped with a low-power receive RF chain to enable the sensing capability for channel estimation. As such, the channels from the BSs/users to the IRS can be estimated at the IRS based on their training signals. To reduce the number of receive RF chains at the IRS, the sub-array technique can be applied where each sub-array consists of a cluster of neighboring elements arranged vertically and/or horizontally and each cluster is equipped with one receive RF chain for channel estimation. Accordingly, the reflection coefficients of all elements in each sub-array can be set to be either the same or different by applying proper interpolation over adjacent sub-arrays.

In contrast, when receive RF chains are not installed at the IRS, it is infeasible for the IRS to estimate the channels with BSs/users directly. However, a viable approach for this challenging case may be that, instead of estimating the IRS-BS/user channels separately, we estimate their concatenated channel with some known IRS reflection patterns (e.g., by turning on/off some of its elements). Alternatively, we can design the reflection coefficients for IRS's passive beamforming based on the feedback from the BSs/users pertaining their received signals that are reflected by the IRS, thus without the need of explicitly estimating the IRS-BS/user channels. For example, the IRS can quickly sweep its reflect beamforming coefficients in a pre-designed codebook and the best beam is then selected based on the BS/user's feedback. To reduce the complexity and time overhead of real-time training, historical data can be exploited. For example, for mmWave communication, due to the channel sparsity [14], the IRS-user channels are usually correlated in space and thus the IRS beamfoming coefficients for users in nearby locations are similar and vary spatially like a smooth function. This can be utilized to obtain the IRS beamforming coefficients for a new user by interpolating those at its nearby locations obtained in the past.

IRS Deployment
How to judiciously deploy IRSs in a hybrid wireless network comprising both active BSs and passive IRSs to optimize its performance is another crucial problem to solve. Generally speaking, this problem should have different considerations as compared to that of deploying active BSs/relays in the traditional wireless network. As IRSs are deployed for local coverage only, their operating ranges are usually much shorter than those of active BSs/relays, which makes it easier to practically deploy IRSs without interfering each other. In the following, we provide more detailed discussion on this issue.

First, from the viewpoint of optimizing the performance in a single-cell setup, the IRS should be intuitively deployed at a location with clear LoS from the BS in order to maximize its received signal power for passive beamforming. However, when the IRS needs to support simultaneous transmissions between the BS and multiple users in its coverage region, such a straightforward deployment strategy may not work well. This is because one single LoS path between the IRS and the BS results in a low-rank MIMO channel that cannot support spatial multiplexing for the transmission to multiple users via the IRS [4]. Therefore, the deployed location for the IRS is practically preferable to possess a strong LoS path with the BS as well as a sufficiently large number of non-LoS paths for enabling a high-rank MIMO channel, so as to resolve the above trade-off. Besides, the deployment of IRS should also take into consideration the spatial user density, i.e., with a high priority to be deployed in hot-spot areas with a large number of users, as well as the inter-cell interference issue, e.g., when there is an urgent need to deploy an IRS near the boundary of two adjacent cells to help cancel the co-channel interference between them, as shown in Fig. 1.

In practice, the propagation environment may be complicated and each IRS can be associated with multiple BSs. In such scenarios, using good heuristics alone for deploying IRS may be ineffective, while an exhaustive search for the optimal location requires the global CSI at all locations, which is practically difficult to obtain. Ray-tracing based methods can be used to estimate such CSI, but they are computationally costly and also require site-specific information (such as building/floor layout for indoor communication). As such, how to achieve autonomous deployment of IRSs by identifying the most suitable locations for them is a new problem of high practical interest. One promising approach to solve this problem is by leveraging machine learning techniques, such as deep learning (DL). For example, in the training phase, we can deploy IRSs at some properly selected reference locations and collect key performance indicators such as received signal strength measured at different user locations. Such IRS locations and corresponding performance indicators are then used to train a DL-based neural network as the output and input, respectively. Next, in the deployment phase, with the desired performance indicators as the input, the trained DL network is used to predict a set of locations for deploying IRSs. After deploying IRSs at these locations, a new set of performance indicators can be collected and used to further train the DL network to improve its prediction accuracy in the future.

Numerical Results
We consider a BS with M antennas, an IRS with N elements, and one single-antenna user, with their locations shown in Fig. 3. Denote the horizontal distance between the BS and user by d meter (m). It is assumed that the BS-IRS channel is dominated by the LoS link with the path loss exponent of 2.2, whereas both the BS-user and IRS-user channels are assumed to follow Rayleigh fading with path loss exponent of 3.2. The receiver noise power is −80 dBm.

Signal Power Enhancement and Scaling Law
To demonstrate the signal power enhancement capability of IRS, we assume that the user in Fig. 3 needs to be served by the BS with the IRS's help, similar to the first scenario in Fig. 1. We compare the following four schemes under the setup of M=5 and N=40:

Joint optimization as in [4]

BS-user maximum-ratio transmission (MRT) where the BS beams toward the BS-user channel

BS-IRS MRT where the BS beams toward the BS-IRS rank-one channel

Benchmark scheme without the IRS where the BS beams toward the BS-user channel.

As shown in Fig. 4, by varying the value of d, we examine the minimum transmit power required at the BS for achieving a target user signal-to-noise ratio (SNR) of 20 dB. First, it is observed that for the scheme without IRS, moving the user farther away from the BS leads to higher transmit power due to the increased signal attenuation. However, this issue is alleviated by deploying the IRS, which helps significantly improve the SNR when the user is near to it. As a result, the user near either the BS (e.g., d=25 m) or IRS (e.g., d=50 m) requires lower transmit power than a user far away from both of them (e.g., d=40 m). This demonstrates the practical usefulness of IRS in creating a “signal hotspot” in its vicinity. Furthermore, compared to other heuristic BS transmit beamforming schemes, the joint active and passive beamforming design achieves substantial power saving at the BS.

In Fig. 5, we show the performance of the IRS where each element reflects with unit amplitude, but using a practical b-bit uniformly quantized phase shifter. The BS transmit power is plotted versus N when d=50 m. First, it is interesting to observe that for the ideal continuous phase, the BS transmit power scales down with N approximately in the order of N2. For example, for the same user SNR, a transmit power of 2.5 dBm is required at the BS when N=150 while this value is reduced to about −3.5 dBm when N=300, which suggests an approximate 6 dB gain by doubling N. Second, one can observe that the performance loss due to finite-level phase shifters with b=1 or b=2 first increases with N and eventually approaches a constant value, that is, 3.9 dB and 0.9 dB, respectively, which are consistent with the results given in [13].

We foresee that the integration of IRSs into future wireless networks will fundamentally change their architecture from the traditional one with active components solely to a new hybrid one with both active and passive components co-working in an intelligent way, thus opening fertile directions for future research.

Interference Suppression
Next, we demonstrate the interference suppression capability of IRS, by considering now the BS in Fig. 3 is a neighboring transmitter that causes co-channel interference to the user when d=50 m, and the IRS is deployed to help suppress its received interference from this BS, like the third scenario in Fig. 1. This setup also resembles the physical layer security scenario in Fig. 6, where the user is an eavesdropper and its received signal from the legitimate transmitter (BS) needs to be canceled with the help of the IRS. For simplicity, we assume M=1 and the transmit power of the BS is 30 dBm. For comparison, we plot the interference power at the user versus N for three schemes as shown in Fig. 6. It is first observed that as compared to the scheme without IRS, the interference power is substantially reduced even by adjusting the phase shifts of the IRS's elements solely. Moreover, with jointly optimized amplitude and phase shifts, it is observed that the co-channel interference can be more effectively canceled as compared to the case with fixed amplitude, especially when N is sufficiently large. This is because with the additional amplitude control, the IRS is able to impose an opposite interference signal at the user to perfectly cancel that from the BS-user link, thus creating a virtually “interference-free zone”.

Conclusions
In this article, we provide an overview of the promising IRS technology for achieving a smart and reconfigurable environment in future wireless networks. Notably, the IRS can sense the wireless environment and accordingly adjust its reflection coefficients dynamically to achieve different functions by leveraging advanced signal processing and machine learning techniques. As IRS-aided wireless networks are new and remain largely unexplored, it is hoped that this article would provide a useful and effective guide for the future research on them. In particular, we foresee that the integration of IRSs into future wireless networks will fundamentally change their architecture from the traditional one with active components solely to a new hybrid one with both active and passive components co-working in an intelligent way, thus opening fertile directions for future research.

Virtual Influencers in Online Social Media

Abstract:
Influencers are people on social media that distinguish themselves by the high number of followers and the ability to influence other users. While influencers are a long-standing phenomenon in social media, virtual influencers have made their appearance on such platforms only recently: they are CGI characters that act like and resemble humans, even if they do not physically exist in the real world. This recent phenomenon has sparked interest in society, and several questions arise regarding their evolution, opinions, ethics, purpose in marketing, and future perspective. In this article, we conduct an exhaustive review of the virtual influencer phenomenon. Through an extensive study of the literature, press articles, social platforms data, blogs, and interviews, we give a comprehensive reflection on virtual influencers. Starting from their evolution, we analyze their opportunities and threats. We provide detailed information about the most popular ones and their marketing collaborations, with a comparative analysis of virtual and real (human) influencers. Moreover, we conducted an online survey to grasp people's perspectives. From the 360 participants' answers, we draw conclusions about virtual influencers' ethics, importance, overall feelings, and future. Results show controversial opinions on this recent phenomenon.

Introduction
As social media spread among people, compa-nies began to embrace them as advertising tools. Marketing agencies rely on people with a high number of followers and ability to influence the masses (known as influencers) for advertisements. The usage of visual content on these platforms has increased in the last decade, especially on lnsta-gram, which became an effective way for brands to literally show their products and values. Con-stant innovation in the influencer marketing industry has led to a new phenomenon called virtual influencers (VIs). We can describe a VI as a person or thing created by software that can influence oth-ers, primarily through marketing collaborations or participation in social campaigns, and is solely cre-ated and consumed via digital mediums [1]. They resemble human characteristics, behavior, and actions but do not correspond to any human in the real world. Companies are not releasing information about the software or technology they use to create VIs. However, we expect they are created by 3D artists using computer-generated imagery (CGI) and motion capture technologies to depict them as real people in real situations. Sometimes, VIs are digitally altered versions of real people or a digital combination of a CGI-made head and a real person's body. We presume that even content related to VIs (e.g., posts), which nowadays is mainly created by humans, will always be more gener-ated by artificial intelligence (AI). In the following sections, we refer to the above definition of VI.

The authors conduct an exhaustive review of the virtual influ-encer phenomenon, Through an extensive study of the literature, press articles social platforms data, blogs, and interviews, they give a comprehensive reflection on virtual influencers

One recent study stated that people like or comment on VIs' posts three times more than real (human) influencers' (RIs') ones. This trend began in 2019 and was consistent in 2020 as well [2]. In the past three to four years, brands from every industry have exploded Instagram with digital ava-tars, demonstrating their commitment toward inno-vation and creativity. Examples are Renault, IKEA, Prada, and Samsung. During the difficult time of the COVID-19 pandemic, VIs contributed to raise awareness about social distancing and other ways to help prevent COVID-19 from spreading [3]. Although the COVID-19 pandemic decelerated the growth of RIs worldwide, VIs were not affected. In reality, the COVID-19 crisis probably fueled the expansion of the VI marketing strategy. Peo-ple are clearly attracted to VIs, given the growing trend of companies partnering with them. Viewers probably like the human emotions VIs express in daily life situations, although they are not real. Fur-thermore, VI can digitally be anywhere at any time, delivering their followers highly catchy content.

Contribution
We provide a wide overview of the emerging phenomenon of VIs under several aspects: evolution, popularity, marketing, ethics, opportunities, and threats. For this purpose, we col-lected and analyzed several literature articles, online resources, and reports provided by websites special-ized in influencers' analysis. Moreover, we carried out a comparative analysis between real and virtual influencers. Finally, we conducted a survey with 360 participants to understand people's views on VIs.

Structure
We first introduce the history and evolution of VIs. Then we present some of the most popular VIs, followed by a discussion on their marketing. Next, we analyze the differences between real and virtual influencers. Last, we con-sider opinions about VIs, concluding the article by presenting some future directions.

Virtual Influencers Timeline
To show the birth and evolution of VIs, we reconstructed a timeline (Fig. 1) of significant events related to virtual characters. Figure 2 shows exam-ples of them, which we now describe. Although the connection between virtual characters and VIs has not been demonstrated in the literature, their similarity allows us to consider virtual characters as predecessors of VIs.

The phenomenon of virtual characters existed way back in the early 1990s, with cartoon characters being the pioneers. Animation has been used as an advertising tool since the 1940s, given the high viewer engagement it creates. However, the first virtual celebrities were launched in Japan along-side virtual idols, which are media performances that occur independently of any living performer's referent [4]. The Japanese talent agency HoriPro teamed up with Visual Science Laboratory, a Computer graphics company, to create Kyoko Date, the world's first 3D computer-generated female model [5]. Kyoko released her first CD single, “Love Communication,” which was well received on Japanese radio. Another popular virtual idol is Hatsune Miku (Fig. 2). She was considered very well known in the world of character entertainment [6]. Hatsune Miku, or Miku Hatsune, which translates to “first sound from the future,” is a virtual singer brought to life in 2007, developed by Crypton Future Media using Vocaloid, a Yamaha voice synthesizer program. Her popularity skyrocketed, prompting her to record her own music in live concerts like any other pop star.

Virtual idols grew rapidly, resulting in the birth of virtual YouTubers in early 2016. A virtual YouTuber, or “Vtuber,” is a fictional character in YouTube videos and live streams. These are 3D models that most commonly exist in digital form and are typically associated with some voice to provide vocal performances [7]. With 3 million subscribers on YouTube, Kizuna AI (Fig. 2) is one of the most famous Vtubers. She has served as a spokeswoman for SoftBank and the Japan Nation-al Tourism Organization, hosted offline fan events, performed at music festivals, and was engaged in a talk with lapanese Nobel Prize winners.

In 2016, a relatively new phenomenon known as virtual influencers emerged, which can be thought of as an evolution of virtual idols and virtual You T u-bers. Since most of the virtual characters were used as influencers, this phenomenon quickly gained traction on Instagram, which is one of the most effective platforms for influencer marketing [8]. These characters were more appealing than virtual idols because of their realistic human-like appearance. Moreover, they were actively involved in marketing and social campaigns, and thus identified as “influencers.” Lil Miquela (Fig. 2), launched in mid-2016, amassed more than 3 million followers on Instagram [9]}. Fol-lowing her success, many other VIs were created. In this article, we mainly focus on VIs.

Popular Virtual Influencers
Nearly 70 percent of brands use influencers on Ins-tagram for their marketing campaigns, compared to around 45 percent on TikTok and Facebook [8]. This could be one reason for VIs to be highly active on Instagram compared to other social media. Hence, we focus more on Instagram in this study. Table 1 provides information of top seven most popular VIs present on Instagram, based on the number of followers and collaborations with famous brands. Fig-ure 3 shows all of them. The table is reconstructed using multiple sources on the Internet. The number of followers and the engagement rate are referred from HyperAuditor, a website that offers a compre-hensive Instagram account analysis report. Here, engagement rate refers to the percentage of the audience who likes or comments on the posts. Birth date, origin, creator, and brand collaborations are sourced from VirtualHumans, a website that provides detailed information about VIs. The estimated per post earnings of each VI is calculated based on the engagement rate and the number of followers using an online tool (Instagram Influencer Earnings Calcu-lator). We now analyze the VIs reported in Table 1.

Lu Do Magalu
Lu made her YouTube debut in 2009, promo-ting iBlogTV on behalf of Magazine Luiza (“Magalu”), one of the largest Brazilian retail firms. Lu has been featuring unboxing videos, prod-uct reviews, and technological tips on behalf of the company. Although Lu has a low engagement rate of 0.08 percent, possibly because she is only famous in Brazil, she has a massive audience of 5 million followers on Instagram. She is also famous on Twitter and Tik Tok. Lu has worked with several fashion companies and supports social causes such as cancer, diversity, and violence against women.

Lil Miquela
Miauela Sousa is a 19-year-old Brazilian-American influencer who debuted on Instagram in 2016, with more than 3 million followers [9]. She is a CGI character developed by Brud, a Los Angeles-based company. She describes herself as a “musician, change-seeker, and drip robot.” Lil Miquela has collaborated with American music producer Baauer on the “Hate Me” album, and her Spotify page has gained a huge amount of monthly listeners. She supports social issues such as Black Lives Matter and trans-gender rights. Time magazine named her one of the Internet's 25 most influential people in 2018, alongside Donald Trump and Kanye West.

Knox Frost
Knox Frost, a 20-year-old “guy” from Atlanta with over 800,000 Instagram followers, is a top male VI. His content over Instagram sparks vibrant discussions in the comments sections of his posts. He has often provided his advice in supporting some social matters like self-empowerment and mental health. He also collaborated with the World Health Organization (WHO) on the COVID-19 public awareness and fundraising campaign.

Thalasva Pov
Thalasva Pov was brought to life in Indonesia in 2018. Since then, she has nearly hit around 500,000 followers. Magnavem Studio developed her, and she now owns a clothing store (Yipiiii). She is dressed as a typical Indonesian influ-encer, often sharing photos of herself in cafes and tourist attractions. She has also partnered with RIs such as Gilang Dirga and Raditya Dika, and has been a Chocolatos brand ambassador, sporadically sharing pictures of herself enjoying the snack.

Imma
Imma was developed by Aww Inc., a Japanese startup that produces virtual influencers. She was featured on the cover of CGWorld maga-zine and has gained more than 300,000 followers. Imma has partnered with several famous compa-nies to promote their products and services. She is well known for her edgy street-style images with very catchy expressions and poses. She looked so real in a photograph alongside two other actual human models in a makeup spread for Kate cos-metics that it was impossible to tell she was a virtu-al character. She also supports Black Lives Matter.

Bermuda
Bermuda was brought to life in 2016 in Los Angeles. She is another creation of Brud. She has the highest engagement rate of 7.29 percent among all VIs and aims to inspire more women to pursue careers in robotics. She is also a rapper with tracks available on Spotify, and is also known as “The Most Controversial” VI. Bermuda once hacked Miquela's account, gaining both of them more followers and driving Mique-la's account past the million-follower mark. This attack was assumed to be a marketing strategy by Brud to gain attention.

Shudu
Shudu is the world's first digital supermodel created by British photographer Cameron-James Wilson, the founder of The Diigitals Agency. She has over 200,000 followers on Instagram with a signifi-cantly higher engagement rate of 3.12 percent as compared to some of the most popular VIs. Shudu has also landed some major brand collaborations.

Influencer Marketing
Influencer marketing is a phenomenon where companies approach famous or high-influence people on social media for brand or product endorsements, extending the “word of mouth” marketing strategy. Influencers are content cre-ators who have built their own personal brand image both online and offline, and are able to drive people's purchasing decisions. The influenc-er marketing industry is expected to rise in value to $13.8 billion by 2021, which is almost 10 times to what it was in 2016 [8].

Big companies and major brands are moving toward digitalization by creating or partnering with VIs. Lil Miquela, one of the most famous VIs, has col-laborated with companies such as Prada and Calvin Klein, alone or alongside RIs. Her estimated earnings per post (EEP) range from 6056to10,093, indicating her enormous success and popularity. Lu, who is the spokesperson of Magazine Luiza, has also collab-orated with the fashion store Zattini for their winter collection clothes. Her EEP of 10,000isprobablyhigherthanthoseofmanyRIs.Shudu,theworld′sfirstdigitalmodel,hasworkedforfamousbrandslikeEllesseandthehigh−endluxuryfashionhouseBal−main,withanaverageEEPofabout 700-$1000. Even during the COVID-19 pandemic, where the whole world (including most RIs) was at a standstill, some big brands collaborated with VIs. The WHO partnered with Knox Frost to disseminate best prac-tices against COVID-19. He supported the COVID- 19 fundraising campaign in his Instagram feed, by also including a link to the WHO's donation page [3]. Another big “virtual” collaboration during the COVID-19 pandemic involved IKEA. They inaugurated a new store in Tokyo with the help of Imma. Imma has also collaborated with various well-known firms, including Magnum, Porsche, and Amazon Fashion. The above collaborations are just examples of how companies are moving toward “virtual” partnerships. Due to VI flexibility and increasing popularity, we expect to see more collaborations in the future.

Virtual Vs. Real Influencers
In this section, we present some opportunities and threats of using VI, a comparative analysis between VIs and real (human) influencers (RIs), and VI ontology and ethics.

Opportunities of Virtual Influencers
More Flexibility
VIs are completely flexible and adaptable. Creators can use VIs in whatever pro-motional capacity they wish, placing them at any place and at any given time. On the contrary, RIs are constrained by factors such as photograph-ic expertise and modeling abilities. During the COVID-19 pandemic, VI flexibility helped them to remain active in posting innovative content, while RIs were confined to their homes.

Exclusivity
VIs can be produced specifically for one particular brand and remain connected to it forever. On the other hand, RIs often work with several brands simultaneously and are not solely known or affiliated with them.

Brand Safety
Since VIs are digitally created, brands can customize VI personas to suit their image and comply with their brand values. This reduces the company's risk of exposure due to inappropriate behavior or the tainted past of an RI. This also avoids VIs from publishing any mate-rial that is against the brand or its messages.

Brand Innovation
Among younger audiences, companies that partner with VIs are perceived as being more innovative and tech-savvy than those that work with RIs.

Threats of Virtual Influencers
Unrealistic Expectations
VIs are prone to inflating people's perceptions. By redrawing expectations for appearance, style, and culture, adolescents could feel forced to imitate and follow those standards. This could negatively affect the audience's mental and physical health without considering that these digital creations do not physically exist in the real world.

Unrealatable
The relationship that consumers may develop with VIs could be limited. Fans would never meet their favorite VI, and could also perceive a lack of human touch since it is not real, which can harm brand loyalty [1].

Authenticity
Authenticity, trust, and transparency are important values for any influencer. In the case of VIs, is it possible for a VI to suggest a product that they have not physically tested? A VI will never try on an outfit, a makeup set, or a weight loss product since they are just digital creations. This raises suspicions about VIs' trust-worthiness and authenticity.

Costs
Considering the costs besides the partnership itself, content generation is very expensive for VIs. Experts in computer graphics are always required behind their actions, who obviously need to be paid. On the contrary, RIs can produce a lot of content with minimal effort, and therefore be more active.

Top Real Vs. Virtual Influencers
We now compare RIs and VIs by analyzing the best representative of both categories. In particular, we focus on top-three VIs/RIs (i.e., with the highest number of Instagram followers and collaborations with famous brands). We considered Lu do Magalu, Lil Miquela, and Knox Frost for the VIs, and Kylie Jenner, Cristiano Ronaldo, and Ariana Grande as the top RIs. The comparison is based on reports released by HypeAuditor, summarized in Table 2.

The difference in the number of followers of real and VIs is evident. Lu do Magalu, the most popular VI, has 5 million followers, while Kylie Jenner, the least popular RI we considered, has ~228 million followers. This huge discrepancy prob-ably reflects that many popular RIs are celebrities outside Instagram, while VIs only exist in social platforms' scope. Furthermore, VIs joined these platforms late compared to RIs, and many peo-ple still ignore their existence. Even the followers' growth is substantially different. RI growth was stable around 30 percent in the last year, while for VI, it fluctuates from very high increases (e.g., 65 percent Lu do Magalu) to a substantial decrement (e.g., ~ 39.7 percent Knox Frost). People might have unfollowed the influencer because of its content, or the account lost bots. In fact, it is estimated that only around 60 percent of the followers of VIs are real people, while the value increases for RIs.

The estimated reach expresses the number of people who usually see an influencer post. RIs present higher values because of their high-er number of followers, but the percentage over the total number of followers is similar to the VI one (from 5 to 30 percent). The same applies to the engagement rate. What differs is the diversity of the population they reach. RIs are followed in many different countries, while the majority of VIs' audience usually comes from their origin country (e.g., Lu do Magalu's audience is mostly Brazilian). Finally, the EEP is substantially higher for RIs, which is expected due to their huge number of followers.

Ontology and Ethics
Defining the ontological status of VIs is challenging. A recent study claimed no meaningful differ-ence between RI and VI [10]. Although VIs do not physically exist, they have a unique identity well defined on social media, and their followers inter-act with them as with any RI. However, VIs are still considered just company tools since their content is designed and created by the humans managing them. This status might change once VIs start using AI to generate their content.

Virtual influencers' ontological status raises challenging ethical questions. Regarding their motivation, if creating “fake” identities for busi-ness might be questionable, this is not meaningfully different from RIs exaggerating and proposing the best version of themselves [10]. Further, even if the VI business model is transparent (i.e., more followers means higher prices for their usage), the secrecy behind their management threatens both RIs and audiences. The former would see Vis as unfair competitors; the latter might find VI communication deceiving. Finally, at present, the moral and legal responsibilities of human-con-trolled VIs are difficult to define, and this will be even more challenging for AI-driven VIs.

Opinions About Virtual Influencers
This section reflects upon some people, creators, and VIs' opinions for or against VIs. We analyzed people's opinions by conducting a survey.

People's Opinion on Virtual Influencers
In [11], the authors interviewed several people to understand their thoughts about VI, who both supported and opposed them. Many respondents agreed that it was hard to trust a VI since it pre-tends to be real while it is not. The novelty and higher engagement of VIs was appreciated, but the lack of authentic content and the impossibility to meet VIs were prominent.

To have a wider understanding of people's thoughts about VIs, we conducted a survey tar-geting social media users. We used an online platform to recruit participants, receiving 360 valid answers from 37 countries. Participants' ages ranged from 16 to 61 (avg 26.3, std 7.7), divided into 169 females, 186 males, and 5 others. We validated answers through several attention checks. The survey had four sections: general, marketing, ethical, and evaluation of VI posts.

General Questions
We started the section by asking: “Have you ever heard about Virtual Influ-encers? (e.g., Lil Miquela, Lu do Magalu).” 38.6 percent of the participants responded positively, highlighting how the phenomenon is still new and unripe. Moreover, only 16 percent follow at least one VI on socials, and less than 7 percent three or more. A big portion of positive answers came from countries in North America, such as the United States and Mexico, in which VIs were first developed. This section highlighted that people would follow a VI mainly for curiosity and fun, rather than to learn something or feel closer to them. More-over, participants would find it important to see relatable and authentic content from VIs (aspects taken for granted with RIs). RIs are expected to deliver more frequent updates and ways of com-municating with their followers. Finally, viewers slightly prefer VIs to look more like a real person than a cartoon character and think they should pri-marily publish content on technology, fashion, daily life, and social matters.

Marketing Questions
While 70 percent of the participants believe a company must have an RI sponsoring them, only 20 percent think the same for VIs. People think a VI could give more flexibility to the company and boost its exclusivity, innovation reputation, and brand safety. Still, only 12 percent of people would trust a VI equally or more than an RI. Rather, 45 percent stated they would trust a VI depending on the context, 27 percent always less than an RI, and 15 percent would never trust them.

Ethical Questions
• In case the behavior of VI appears unethical, only 26 people would con-demn the VI itself, while most participants would accuse both the VI creator and the company using it. In general, people like to see VIs supporting social issues (e.g., civil rights, gender inequality) but are reluctant if the supported cause is person-al or closer to them. This reflects the 60 percent of participants thinking it is impossible to build a relationship with a VI (33 percent answered “Maybe”). Finally, only 15 percent would chat with a VI, 30 percent maybe, and 55 percent not.

Virtual Influencers' Posts Evaluations
In this section, we presented three posts created by three VIs (Fig. 4), asking for a value from 1 (low) to 5 (high) for the following aspects: authenticity, relatability, innovative content, attractive content, comparable to an RI, and overall evaluation. Knox Frost's post, which depicts him while composing music, on average was considered the most authentic, relatable, and innovative. This might be related to the theme of the picture (i.e., composing music, which might be accepted for a virtu-al character), and the influencer wearing a mask during the COVID-19 Pandemic. Lil Miquela's post received the highest votes for attractive content, while Bermuda's was voted the most similar to RIs' posts. Overall, Knox Frost's post was better accepted by the participants, but many others stated that VIs and their similarity with RIs scare them, revealing a general negative feeling.

Creators'Opinions
Cameron-James Wilson claims he never intended to mislead anyone by creating Shudu. He described her as an “art piece” and a “virtual” cel-ebration of attractive, dark-skinned women [12]. Wilson tried to recreate the elegance embodied by black supermodels as a fashion photographer. He further added that he created Shudu with 3D modeling software and would like to think of her as a mannequin. “You can pose her and give her an expression once you've finished creating her,” he said.

Hirokuni Miyaji, the creator of the VI Liam Nikuro, explained that he wanted to demon-strate what “we can do” for businesses [13]. Their motive is to raise awareness and get brands excited to collaborate with them on their own virtual humans rather than make Liam famous. He also shared his long-term plan for Liam, which is to introduce AI and allow him to interact with real people. Eventually, he stated that the distinction between fictional influencers and RIs will become increasingly blurred in the future. Only the con-tent will be important.

Virtual Influencers' Opinions
Besides the creators, even VIs are opening up for interviews to talk about themselves and what they stand for. With the help of interviews conducted with the VIs Lil Miquela and Lu do Magalu, we would like to highlight some of the opinions that these VIs have about themselves. In an interview, Lu was asked “Who are you?”; she replied saying “I'm a strong, virtual woman who creates content to share her knowledge and her causes with everybody.” She further added that she loves assisting people and is fascinated by technology, and innovation and is hon-ored to serve Magalu [14]. A similar question was asked to Miquela, and she answered saying “I'm an artist and have expressed opinions that are unpopu-lar and as a result, have cost me fans.” Furthermore, she would love to do everything that her fans want, but ultimately, she would have to make choices that she believes in [15]. We may conclude that there is almost no difference between interviews conducted with a human being and those conducted with a virtual character. They are questioned in the same way as a real person would be, and these VIs have responded close to how a real person would.

The Future of Virtual Influencers
Our research showed the rising trend of VIs. With the ever increasing coexistence of human and virtual beings, like in virtual reality applications or the metaverse, we expect the VI phenomenon to continue growing. We believe techniques used on social media by RIs, in general, can be applied to VIs as well to increase their impact. Howev-er, several concerns still exist in people's minds regarding the transparency and authenticity of VIs. facts that were confirmed by our survey.

The majority of VIs are currently CGI-made, limiting audience interaction to static social media posts or videos. Nevertheless, with advancements in AI and virtual reality, some VIs are already par-ticipating in live interviews and activities, becoming more “human.” AI-driven VIs will raise ethical concerns worth discussing in the future.

Further VI analysis might focus on their con-tent, such as determining whether it is AI-generated or made by humans, and whether consumers will notice and embrace AI-generated content. Finally, VIs' impact on existing communication technologies, systems, or services should be eval-uated; for example, how their behavior changes on different communication platforms, or whether companies will develop new systems to increase their functionalities.

Network Digital Twin: Context, Enabling Technologies, and Opportunities

Abstract:
The proliferation of emergent network applications (e.g., telesurgery, metaverse) is increasing the difficulty of managing modern communication networks. These applications entail stringent network requirements (e.g., ultra-low deterministic latency), which hinders network operators in managing their resources efficiently. In this article, we introduce the network digital twin (NDT), a renovated concept of classical network modeling tools whose goal is to build accurate data-driven network models that can operate in real time. We describe the general architecture of the NDT and argue that modern machine learning (ML) technologies enable building some of its core components. Then we present a case study that leverages an ML-based NDT for network performance evaluation and apply it to routing optimization in a QoS-aware use case. Lastly, we describe some key open challenges and research opportunities yet to be explored to achieve effective deployment of NDTs in real-world networks.

Introduction
In this article, the authors introduce the network digital twin (NDT), a renovated concept of classical network modeling tools whose goal is to build accurate data-driven network models that can operate in real time.
In recent years, the digital transformation of both society and industry has led to the emergence of novel network applications. These applications have complex requirements that cannot easily be met by traditional network management solutions at a reasonable cost, such as network overprovisioning or admission control. For example, novel forms of communication such as augmented/virtual reality (AR/VR) and holographic telepresence require ultra-low deterministic latency, while recent industrial developments (e.g., vehicular networks) need to adapt to ever changing network topologies in real time. At the same time, the number of connected devices is growing massively, making modern networks highly dynamic and heterogeneous. As a result, communication networks are becoming increasingly complex and costly to manage.

Other industry sectors have recently adopted the digital twin (DT) paradigm [1] to model complex dynamic systems. A DT can be understood as a virtual model of a physical object, system, or phenomenon that is represented in the digital world. The main advantage of DTs is that they can accurately model complex systems. Nowadays, DT applications include enabling smart manufacturing in Industry 4.0, improving the performance of complex engineering products (e.g., engine design), and modeling physical interactions (e.g., gravitational systems).

This article makes the case for the network digital twin (NDT) as a key enabler for efficient control and management of modern communication networks. NDTs can be applied to many fundamental networking applications. As an example, they allow network operators to perform online network optimization, what-if analysis, trouble-shooting, or plan network upgrades considering the expected natural growth of the network. The interaction with the NDT does not require access to the real network, so the aforementioned operations can be performed without jeopardizing the physical network.

Recent machine learning (ML) models have shown outstanding capabilities for modeling complex systems. For example, in communication networks, ML has already been successfully applied to network modeling [2], traffic optimization in data centers [3], [4], network slicing [5], and resource allocation in wireless networks [6]. In this context, we argue that modern ML techniques are a key enabler to build core components of the NDT.

NDTs aim to achieve accurate data-driven network models operating in real time [7], [8]. In this vein, the use of ML enables training network models directly with real network data, avoiding the strong assumptions of analytical models (e.g., queueing theory). ML models can thus help achieve similar accuracy to traditional computationally expensive modeling tools (e.g., packet-level simulation) while keeping a limited execution cost similar to lightweight analytical models. This allows network operators to accurately control the network at much shorter timescales.

There is a growing interest in the networking community in building NDTs. In particular, standards development organizations (SDOs), such as the Internet Engineering Task Force (IETF) and the International Telecommunication Union (ITU), have started to work on the definition of an NDT [7], [8]. While their work focuses on defining the main concepts and interfaces of an NDT, this article focuses on the technologies and research challenges involved in implementing an ML-based NDT, complementing the work of SDOs.

The Network Digital Twin
NDTs are referred to as a new generation of network modeling tools that leverage ML techniques to build an accurate data-driven digital network representation [7], [8]. To train these network models, we can use data from real-world networks, dedicated network testbeds, or network simulation tools. This data should be diverse enough to cover a wide representation of potential scenarios that the network operator wants to mimic (e.g., various congestion levels, link failures). In this context, recent deep learning (DL) techniques are of interest as they enable building accurate digital models of complex network environments [2], [3].

Figure 1 presents the reference architecture of the NDT. The central component of the architecture is the DT, which implements a network model that mimics the physical network. This model takes as input a network state description (e.g., traffic, topology, routing, scheduling policies) and outputs some network-related metrics or features (e.g., utilization, delay, anomalies). Since the NDT is a faithful copy of the real-world network, the network operator can test any input values, even if these values might cause service disruptions. This is because the NDT is executed in a safe environment isolated from the real-world network. The outputs can be of multiple types depending on the applications of the NDT (e.g., time series, link-level predictions, global network-level metrics). Note that the example depicted in Fig. 1 illustrates the case of an NDT applied to a fixed network, while analogous architectures could be applied to other kinds of networks, such as wireless/cellular networks. As an example, Table 1 shows a description of some generic networking use cases that can take advantage of NDTs for efficient network control and management.

Leveraging Machine Learning to Build NDTs
In this article, we argue that ML techniques are a key enabler to build core components of the NDT. In particular, recent DL models offer several advantages with respect to traditional network modeling tools (e.g., simulators, queueing theory [QT]). As an example, DL-based models have shown state-of-the-art performance when modeling fixed networks [2], outperforming well-known analytical models based on QT. In addition, they are easy to parallelize and have a low execution cost compared to traditional network simulation tools (e.g., OMNet++, ns-3).

Graph neural networks (GNN) are a DL-based architecture recently proposed by the ML community to model relational information [9]. GNNs capture graph dependencies using a message passing algorithm between the graph's entities (nodes and edges). Since communication networks are fundamentally represented as graphs, GNNs offer unique advantages for network modeling when compared to traditional NN architectures (e.g., multilayer perceptron, recurrent NN). In the last years, GNNs have demonstrated outstanding performance to solve a wide variety of network-related problems [2], [5], [6], [10], [11]. In this context, GNNs may be a central technology to enable the construction of ML-based network models that can generalize to different network topologies, configurations, and traffic distributions.

Network Optimization with the NDT
The NDT can be combined with a network optimizer to solve different tasks (e.g., traffic engineering, network anomaly detection, network planning). Specifically, optimizers can use the NDT to obtain immediate network performance estimations during an optimization process. Figure 2 summarizes this process. First, the network operator uses a declarative language to define the network requirements (e.g., load balancing). The optimizer is in charge of searching for the best network configuration that fulfills the predefined requirements (step 2). If the performance metrics from the NDT indicate that the solution is not good enough (step 3), the network optimizer continues the search until a stopping condition is met. Lastly, the best solution found so far can be applied to the real network (step 4). Notice that the optimization process can be implemented as a closed loop, with no human intervention required.

Real-world networks are highly dynamic as their traffic, applications, resource utilization and topology constantly changes over time. For example, physical links may break due to external factors, or network users can have different behavior patterns that cause difficult-to-predict spikes in the utilization of network resources. Therefore, to enable efficient network management, it is important for the optimizer to adapt to such changes in real time.

In this context, deep reinforcement learning (DRL) is a key technology that has shown great capabilities for efficient network operation in dynamic scenarios [3], [4], [11]. However, in complex optimization problems, DRL often produces sub-optimal solutions. For example, in resource allocation problems, it can be challenging to find the optimal network configuration that optimizes some performance metrics. This is because the solution space (i.e., the number of possible actions) might be very large, and more comprehensive exploration strategies are needed to find the optimal solution. Several works started combining DRL with traditional optimization methods (e.g., integer linear programming) to improve the optimization performance [10].

Training the Digital Twin
Building an NDT requires collecting a dataset that contains relevant information of the network. The NDT's accuracy highly depends on the quality of the data, requiring the training dataset to contain a representative set of samples with different network characteristics. For example, if the goal is to model the delay of network traffic, the dataset has to include a wide range of network scenarios and its impact on the delay. This may include different routing configurations, topologies, scheduling, and traffic loads. Likewise, the dataset should cover edge cases that may negatively impact the delay, such as link and interface failures, misconfigurations, and highly congested scenarios.

Another important aspect to consider is, how do we generate this dataset? Fundamentally, the dataset can be obtained from real-world networks, non-production dedicated testbeds, or simulation tools. However, generating such training sets in production environments may be impractical. As mentioned previously, the dataset must contain edge cases that may be unacceptable to reproduce in real-world networks as they could cause service interruptions. As a result, we believe that it is more practical to produce the training dataset in non-production environments, such as dedicated network testbeds or simulators. In these controlled environments, the network can be configured with different traffic profiles, failures, misconfigurations, and errors, as well as covering a wide range of valid configurations without disrupting the normal operation of the network.

The main challenge of generating the dataset is that the NDT has been trained in a specific network environment, but when deployed, it has to operate on an unseen customer network. In other words, the NDT has to operate in scenarios that are not explicitly included in the training set. As an example, the topology and traffic profile of the customer network might be different from the ones seen during training in the controlled network environment. In the ML domain, the capability of a model to operate in unseen scenarios is referred to as generalization.

Case Study: Performance Evaluation in Fixed Networks
ML has already been validated for network modeling and optimization in many different scenarios (e.g., fixed networks [2], data centers [3], [4], wireless networks [5], [6]). In this section we present a case study that aims to analyze in more detail the application of a state-of-the-art ML-based NDT for performance evaluation in fixed IP networks. In addition, we perform some experiments where we leverage an ML-based NDT for routing optimization in a quality of service (QoS)-aware optimization use case.

Predicting End-to-End Delay
We take as a reference RouteNet-E [2], a state-of-the-art GNN-based model that accurately predicts delays in networks. This model takes as input a network state description defined by a network topology, a traffic matrix, and a routing policy. As a result, it mimics the network behavior and produces end-to-end delay predictions for all paths.

To train this model, we generate a dataset with 100,000 samples in topologies with 25–50 nodes simulated with an accurate packet-level network simulator (OMNet++). Then we generate a test dataset with 500 samples from considerably larger topologies, with 50–300 nodes uniformly distributed. Network topologies are synthetically generated using the power-law out-degree algorithm, where the α and β parameters have been extrapolated from real-world topologies of the Internet Topology Zoo repository [13]. Traffic loads and link capacities are scaled to cover a broad range of congestion levels, with a maximum packet loss of ≈ 3 percent. As reference baselines, we use a state-of-the-art analytical model based on queueing theory (QT) and a recurrent neural network (RNN). A detailed description of these baselines can be found in Table 2.

Figure 3 shows the evaluation results of the aforementioned models on topologies with up to 300 nodes. The y-axis represents the mean absolute percentage error of the predictions made by the different methods with respect to the ground truth labels produced by the network simulator. Error bars represent the 15/85 percentiles. If we look at the results in topologies of similar size to those of the training (25–50 nodes), we can observe that the two ML-based methods (RouteNet-E and RNN) achieve lower error than the analytical QT baseline, particularly in the case of RouteNet-E.

In this context, a potential limitation of ML-based solutions is that their accuracy is expected to drop when evaluated on out-of-distribution data. In this case, out-of-distribution data refers to topologies, traffic matrices, and routing configurations different from those seen by the ML model during training. Figure 3 shows the evolution of the prediction errors as we increment the network size with respect to the networks seen during training (with 25–50 nodes). We can observe that the RNN model's performance significantly degrades as networks become larger. In contrast, RouteNet-E shows robust behavior when facing samples of considerably larger networks. This is thanks to its internal GNN-based architecture, which enables it to effectively model the relational information within networks and generalize well to larger topologies.

In addition, we compute the inference cost of all methods on off-the-shelf hardware (processor AMD Ryzen 9 3950X with 3.5 GHz) on topologies with 250–300 nodes. As a result, we observe an average execution time of ≈ 0.16, ≈ 5.1, and ≈ 6.47 s for RNN, QT, and RouteNet-E, respectively, while the packet-level network simulator takes ≈ 3 h and 39 min on average.

Overall, the previous results show the potential benefits of modern ML models to produce performance estimates with similar accuracy to simulation methods, while keeping the limited cost of analytical models (e.g., QT), thus enabling fast operation.

QoS-Aware Routing Optimization
In this section, we aim to showcase the potential application of NDTs for optimization in QoS-aware scenarios. To this end, we use the RouteNet-E model used in the previous section. We define the optimization problem as finding the routing configuration that minimizes the average end-to-end delay on paths. We consider a destination-based open shortest path first (OSPF) routing scheme, where the initial routing configuration is the shortest path (i.e., equal weights on all links). To achieve optimization, we follow the reference workflow depicted in Fig. 2. In particular, RouteNet-E represents the DT, while the network optimizer is implemented as an algorithm based on evolutionary strategies [14]. In this architecture, the network optimizer generates variations of the shortest path (i.e., different link weights), and RouteNet-E is intended to predict the resulting delay on paths for those alternative configurations. Thus, the optimizer compares the delay predictions produced by RouteNet-E and finally takes the routing configuration that results in minimum average end-to-end delay.

We evaluate the resulting optimizer in a synthetically generated topology of 25 nodes. Traffic matrices cover a wide range of traffic intensities (from low traffic load to highly congested networks). Figure 4 shows the results of the optimization. Traffic intensity values (x-axis) represent the average traffic volume on paths (in bits per second). The final delay values (y-axis) are computed with the network simulator, used as ground truth in the previous section (Table 2). As the network congestion increases (i.e., more traffic intensity), the network optimizer achieves higher delay reduction with respect to the initial shortest path. These results show that the NDT-based optimizer used in the experiments is able to effectively reduce the end-to-end delay on networks.

Open Challenges and Opportunities
This article has shown that modern ML techniques can be key enablers for building core components of NDTs, as well as described some potential applications of NDTs for a broad variety of networking use cases. However, there are several open challenges that need to be addressed by the research community to enable the deployment of NDTs in real-world networks. Below, we present some key open challenges and opportunities yet to be explored before achieving production-ready NDT solutions.

Data Collection and Storage
One way to improve generalization of NDTs is using well-known ML techniques such as regularization or dropout. However, these methods can impact the performance or introduce a bias in the model. In addition, when the network scenario changes drastically, the NDT can lead to performance degradation.
In a networking context, collecting and processing data is challenging and expensive. This is because it often requires the use of costly telemetry systems to gather relevant network state data. Moreover, data is only valuable if it has a common data format or labeling. However, in real-world networks data typically comes from different sources and has different formats. Thus, it is important to define standard representations and interfaces that can be applicable to different monitoring sources.

One limitation of gathering network-related data is that it can require large amounts of storage. For example, in modern data center networks (with thousands of servers), most traffic flows have a very short duration [15]. Therefore, to consider per-flow records can involve large amounts of data, making their storage and processing unfeasible.

In this context, monitoring platforms often use general-purpose compression methods to reduce the storage needs (e.g., GZIP). However, these methods do not exploit characteristics of traffic traces (e.g., temporal correlations), resulting in poor compression ratios. This calls for the design of special-purpose compression methods that can further help reduce the size of network monitoring data.

Generalization and Scalability to Real Networks
The NDT should be able to perform well on different network scenarios than those seen during training. Generalization is important because training an NDT is not immediate, and network changes can happen very fast (e.g., link failure), so it is not possible to finish the training process before there is a new network event. One way to improve generalization of NDTs is using well-known ML techniques such as regularization and dropout. However, these methods can impact the performance or introduce a bias in the model. In addition, when the network scenario changes drastically, the NDT can lead to performance degradation. This presents an opportunity for the research community to develop new ML models that may lead to more solid generalization. In this context, GNN models have recently shown promising results for generalization across network-related data structured as graphs [2], [6].

Modern communication networks are often larger than the network environments used to generate the training datasets, raising a scalability challenge for ML models. NDTs should generalize well to networks considerably larger than those seen during training (e.g., 1–2 orders of magnitude larger). However, it often involves facing out-of-distribution values (e.g., larger traffic volumes and link capacities), which may degrade the performance of the NDT. Consequently, building scalable NDTs is an open issue that should be addressed to achieve production-ready solutions.

Fine-Grained Control and Management
In order to perform efficient network operation, it is necessary to model network traffic at a low granularity (e.g., flow-based operation). However, communication networks carry a large number of flows simultaneously [15], which may raise scalability issues for ML-based methods. Some networking systems tackle the flow scalability issue by applying traffic sampling or aggregation techniques. This enables the network operator to set a trade-off between the sampling rate used and the accuracy of the statistics collected from the network. Therefore, building flow-based NDT models that can operate at a certain flow granularity and at short timescales is a relevant open challenge for the networking community.

Dealing with Uncertainty
Neural-network-based models are typically seen as a black-box, which hinders the deployment of DL solutions in real-world networks. When a neural-network-based model is evaluated, it is difficult to assess how certain the model is about the predictions made. Given the critical nature of communication infrastructures, such limitations are important as network operators need robust and reliable methods that can be applied to real-world networks without compromising their normal behavior. In this vein, existing works from the ML community attempt to solve this issue by modeling posterior probability distributions on DL models (e.g., Bayesian neural networks). Another alternative is to design comprehensive testing procedures in controlled network environments to systematically determine the safe operational ranges of DL models (e.g., supported traffic volumes) before deployment on customer networks.

Conclusion
This article has introduced the NDT concept and its reference architecture. We have argued that NDTs enable the development of more efficient network control and management tools for modern communication networks. In this context, recent advances in ML permit building NDTs that can accurately mimic the behavior of real-world networks. In this article, we have focused on GNNs and DRL, but we do not limit the application of other existing ML techniques to build market-ready NDTs. However, there are still some open challenges to be addressed for a full-scale NDT deployment in real networks. We encourage the networking community to explore innovative solutions to these challenges.

